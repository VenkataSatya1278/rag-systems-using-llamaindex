{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5325ac27-38ea-47aa-afef-be4ec4f8f4b9",
   "metadata": {
    "id": "5325ac27-38ea-47aa-afef-be4ec4f8f4b9"
   },
   "source": [
    "# Auto Merging Retriever\n",
    "\n",
    "In this notebook, we showcase our `AutoMergingRetriever`, which looks at a set of leaf nodes and recursively \"merges\" subsets of leaf nodes that reference a parent node beyond a given threshold. This allows us to consolidate potentially disparate, smaller contexts into a larger context that might help synthesis.\n",
    "\n",
    "You can define this hierarchy yourself over a set of documents, or you can make use of our brand-new text parser: a HierarchicalNodeParser that takes in a candidate set of documents and outputs an entire hierarchy of nodes, from \"coarse-to-fine\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b73b2d8-d3fd-4081-9f25-368e4bd9b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc23b2b2-f9b4-4453-a189-3a02554b2b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('/home/santhosh/Projects/courses/Pinnacle/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d665388f-61f6-4097-89e3-86ffc36fc8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fbdc26",
   "metadata": {
    "id": "b9fbdc26"
   },
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1316ac-84ca-41d0-80f9-d4ef758e653c",
   "metadata": {
    "id": "7e1316ac-84ca-41d0-80f9-d4ef758e653c"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "Let's first load the Llama 2 paper: https://arxiv.org/pdf/2307.09288.pdf. This will be our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80372299-ab32-4ddd-9b88-05c877120c17",
   "metadata": {
    "id": "80372299-ab32-4ddd-9b88-05c877120c17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-06 18:48:56--  https://arxiv.org/pdf/2307.09288.pdf\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.195.42, 151.101.3.42, 151.101.67.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.195.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://arxiv.org/pdf/2307.09288 [following]\n",
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2024-12-06 18:48:57--  https://arxiv.org/pdf/2307.09288\n",
      "Reusing existing connection to arxiv.org:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13661300 (13M) [application/pdf]\n",
      "Saving to: â€˜data/llama2.pdfâ€™\n",
      "\n",
      "data/llama2.pdf     100%[===================>]  13.03M  6.03MB/s    in 2.2s    \n",
      "\n",
      "2024-12-06 18:48:59 (6.03 MB/s) - â€˜data/llama2.pdfâ€™ saved [13661300/13661300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/'\n",
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f9c5d99-bd0e-4b26-b816-9f5ad29df3c8",
   "metadata": {
    "id": "5f9c5d99-bd0e-4b26-b816-9f5ad29df3c8"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.readers.file import PyMuPDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ea0f83-cb78-444d-a46d-57473ad78fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a526766-d976-4095-90fc-1ab309dc4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs0 = SimpleDirectoryReader(input_files=[\"./data/llama2.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "723f1f02-2157-4166-b013-90e627c76530",
   "metadata": {
    "id": "723f1f02-2157-4166-b013-90e627c76530"
   },
   "outputs": [],
   "source": [
    "loader = PyMuPDFReader()\n",
    "# docs0 = loader.load_data(file=Path(\"./data/llama2.pdf\"))\n",
    "docs0 = loader.load(file_path=Path(\"./data/llama2.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7a8552-f347-45b0-b4a0-4f9b32be57ac",
   "metadata": {
    "id": "ff7a8552-f347-45b0-b4a0-4f9b32be57ac"
   },
   "source": [
    "By default, the PDF reader creates a separate doc for each page.\n",
    "For the sake of this notebook, we stitch docs together into one doc.\n",
    "This will help us better highlight auto-merging capabilities that \"stitch\" chunks together later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a75c4217-ab50-417f-a8ed-3b746a9956c8",
   "metadata": {
    "id": "a75c4217-ab50-417f-a8ed-3b746a9956c8"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n",
    "docs = [Document(text=doc_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724fe6f1-80e1-4ac5-bd99-8b9b8d15bddd",
   "metadata": {
    "id": "724fe6f1-80e1-4ac5-bd99-8b9b8d15bddd"
   },
   "source": [
    "## Parse Chunk Hierarchy from Text, Load into Storage\n",
    "\n",
    "In this section we make use of the `HierarchicalNodeParser`. This will output a hierarchy of nodes, from top-level nodes with bigger chunk sizes to child nodes with smaller chunk sizes, where each child node has a parent node with a bigger chunk size.\n",
    "\n",
    "By default, the hierarchy is:\n",
    "- 1st level: chunk size 2048\n",
    "- 2nd level: chunk size 512\n",
    "- 3rd level: chunk size 128\n",
    "\n",
    "\n",
    "We then load these nodes into storage. The leaf nodes are indexed and retrieved via a vector store - these are the nodes that will first be directly retrieved via similarity search. The other nodes will be retrieved from a docstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45e783f5-a323-4f51-ae9a-4b71b00e5e11",
   "metadata": {
    "id": "45e783f5-a323-4f51-ae9a-4b71b00e5e11"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import HierarchicalNodeParser, SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c3947df-25c2-4254-a3d4-381d136f3f77",
   "metadata": {
    "id": "2c3947df-25c2-4254-a3d4-381d136f3f77"
   },
   "outputs": [],
   "source": [
    "node_parser = HierarchicalNodeParser.from_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2162b309-dfc5-484b-a31c-24f705316f10",
   "metadata": {
    "id": "2162b309-dfc5-484b-a31c-24f705316f10"
   },
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9b5bc9b-389d-47db-a41c-3eb5b3d38ac5",
   "metadata": {
    "id": "a9b5bc9b-389d-47db-a41c-3eb5b3d38ac5",
    "outputId": "74627310-8220-4ec4-e4f2-bd6c21746bab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1009"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7456b70-1803-4786-86d5-26e202e0f318",
   "metadata": {
    "id": "a7456b70-1803-4786-86d5-26e202e0f318"
   },
   "source": [
    "Here we import a simple helper function for fetching \"leaf\" nodes within a node list.\n",
    "These are nodes that don't have children of their own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7299ca7e-09b6-432f-a277-aae9eca0522a",
   "metadata": {
    "id": "7299ca7e-09b6-432f-a277-aae9eca0522a"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import get_leaf_nodes, get_root_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faeb37a8-aea9-4ee8-b6c0-3b2f188d244e",
   "metadata": {
    "id": "faeb37a8-aea9-4ee8-b6c0-3b2f188d244e"
   },
   "outputs": [],
   "source": [
    "leaf_nodes = get_leaf_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c33b5a8-4d9f-481e-8616-fc8717900159",
   "metadata": {
    "id": "7c33b5a8-4d9f-481e-8616-fc8717900159",
    "outputId": "e98e34b1-d89e-406a-d224-b06fe6cbf16a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leaf_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b28b0aff-db6e-495e-8c58-36db29edb45b",
   "metadata": {
    "id": "b28b0aff-db6e-495e-8c58-36db29edb45b"
   },
   "outputs": [],
   "source": [
    "root_nodes = get_root_nodes(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36ec940-8af7-45f5-9994-919d57583c24",
   "metadata": {
    "id": "c36ec940-8af7-45f5-9994-919d57583c24"
   },
   "source": [
    "### Load into Storage\n",
    "\n",
    "We define a docstore, which we load all nodes into.\n",
    "\n",
    "We then define a `VectorStoreIndex` containing just the leaf-level nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27c8f2cd-3e04-4feb-937b-b9ee33e1c2fd",
   "metadata": {
    "id": "27c8f2cd-3e04-4feb-937b-b9ee33e1c2fd"
   },
   "outputs": [],
   "source": [
    "# define storage context\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core.storage import StorageContext\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "\n",
    "# insert nodes into docstore\n",
    "docstore.add_documents(nodes)\n",
    "\n",
    "# define storage context (will include vector store by default too)\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "827ece8e-7a4b-4ee1-8ee2-3433d7f2072a",
   "metadata": {
    "id": "827ece8e-7a4b-4ee1-8ee2-3433d7f2072a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Load index into vector index\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "base_index = VectorStoreIndex(\n",
    "    leaf_nodes,\n",
    "    embed_model = OpenAIEmbedding(model='text-embedding-3-small'),\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d84c19-c9ac-4294-a000-264c3c02427b",
   "metadata": {
    "id": "05d84c19-c9ac-4294-a000-264c3c02427b"
   },
   "source": [
    "## Define Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e61682a0-dd3c-400b-8734-35d5d0a98252",
   "metadata": {
    "id": "e61682a0-dd3c-400b-8734-35d5d0a98252"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers.auto_merging_retriever import AutoMergingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f96fd0bc-c6c0-4073-a692-d1803cf4289f",
   "metadata": {
    "id": "f96fd0bc-c6c0-4073-a692-d1803cf4289f"
   },
   "outputs": [],
   "source": [
    "base_retriever = base_index.as_retriever(similarity_top_k=6)\n",
    "retriever = AutoMergingRetriever(base_retriever, storage_context, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "498d4f2a-3d2c-4b01-8bd0-768a08694a1c",
   "metadata": {
    "id": "62f655cd-4195-4398-80e5-5aa561982d25",
    "outputId": "099c7535-159e-4b42-981d-2fab54c4120b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 17ef2f43-9553-4dca-bc57-e22127535a59.\n",
      "> Parent node text: We conduct RLHF by first collecting human preference data for safety similar to Section 3.2.2: an...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query_str = \"What were some lessons learned from red-teaming?\"\n",
    "# query_str = \"Can you tell me about the key concepts for safety finetuning\"\n",
    "query_str = (\n",
    "    \"What could be the potential outcomes of adjusting the amount of safety data used in the RLHF stage?\"\n",
    ")\n",
    "\n",
    "base_nodes = base_retriever.retrieve(query_str)\n",
    "\n",
    "nodes = retriever.retrieve(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fb9aa77-1f76-4f02-8ca7-679985b1ba38",
   "metadata": {
    "id": "62f655cd-4195-4398-80e5-5aa561982d25",
    "outputId": "099c7535-159e-4b42-981d-2fab54c4120b"
   },
   "outputs": [],
   "source": [
    "# query_str = \"What were some lessons learned from red-teaming?\"\n",
    "# query_str = \"Can you tell me about the key concepts for safety finetuning\"\n",
    "query_str = (\n",
    "    \"What could be the potential outcomes of adjusting the amount of safety data used in the RLHF stage?\"\n",
    ")\n",
    "\n",
    "base_nodes = base_retriever.retrieve(query_str)\n",
    "\n",
    "nodes = retriever.retrieve(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d90db2bf-7651-4152-873e-d10fbd23fee1",
   "metadata": {
    "id": "62f655cd-4195-4398-80e5-5aa561982d25",
    "outputId": "099c7535-159e-4b42-981d-2fab54c4120b"
   },
   "outputs": [],
   "source": [
    "# query_str = \"What were some lessons learned from red-teaming?\"\n",
    "# query_str = \"Can you tell me about the key concepts for safety finetuning\"\n",
    "query_str = (\n",
    "    \"What could be the potential outcomes of adjusting the amount of safety data used in the RLHF stage?\"\n",
    ")\n",
    "\n",
    "base_nodes = base_retriever.retrieve(query_str)\n",
    "\n",
    "nodes = retriever.retrieve(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77eabc56-2009-4504-8832-b6d857bd43a4",
   "metadata": {
    "id": "77eabc56-2009-4504-8832-b6d857bd43a4",
    "outputId": "4729aed3-28ad-4cdf-d0e2-c1fb9b88507a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a82690a-263a-4e48-ab27-b161e72cb983",
   "metadata": {
    "id": "3a82690a-263a-4e48-ab27-b161e72cb983",
    "outputId": "72f1ac53-6024-49a9-9eee-fbd1f36dea7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d482b22-fd38-476b-821f-0c77564815c3",
   "metadata": {
    "id": "0d482b22-fd38-476b-821f-0c77564815c3",
    "outputId": "6bf61dad-bcb8-4d8c-8e85-9f5a26a31e29"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 18cdca60-c495-40ed-90d8-8584451a6b7b<br>**Similarity:** 0.20969704892734822<br>**Text:** Llama 2: Open Foundation and Fine-Tuned Chat Models\n",
       "Hugo Touvronâˆ—\n",
       "Louis Martinâ€ \n",
       "Kevin Stoneâ€ \n",
       "Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\n",
       "Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\n",
       "Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\n",
       "Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** a954be12-18ac-46c1-a375-dfb5c8f947fc<br>**Similarity:** 0.12247519370800712<br>**Text:** Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\n",
       "Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\n",
       "Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\n",
       "Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\n",
       "Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\n",
       "Alan Schelten<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4dd58db-4b12-49dc-b42f-8a0ee746f5c9",
   "metadata": {
    "id": "e4dd58db-4b12-49dc-b42f-8a0ee746f5c9",
    "outputId": "082057d1-6f7a-4166-9407-eee463d45ac0"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 18cdca60-c495-40ed-90d8-8584451a6b7b<br>**Similarity:** 0.20969704892734822<br>**Text:** Llama 2: Open Foundation and Fine-Tuned Chat Models\n",
       "Hugo Touvronâˆ—\n",
       "Louis Martinâ€ \n",
       "Kevin Stoneâ€ \n",
       "Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\n",
       "Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\n",
       "Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\n",
       "Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** a954be12-18ac-46c1-a375-dfb5c8f947fc<br>**Similarity:** 0.12247519370800712<br>**Text:** Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\n",
       "Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\n",
       "Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\n",
       "Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\n",
       "Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\n",
       "Alan Schelten<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for node in base_nodes:\n",
    "    display_source_node(node, source_length=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f62e2c-4def-402e-8904-47f34d12c2fb",
   "metadata": {
    "id": "08f62e2c-4def-402e-8904-47f34d12c2fb"
   },
   "source": [
    "## Plug it into Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d3ce9ec-f6cd-475b-94fa-3e8df81ab824",
   "metadata": {
    "id": "5d3ce9ec-f6cd-475b-94fa-3e8df81ab824"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f106e1bb-58bc-48bf-a46b-e527339f83c5",
   "metadata": {
    "id": "f106e1bb-58bc-48bf-a46b-e527339f83c5"
   },
   "outputs": [],
   "source": [
    "query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "base_query_engine = RetrieverQueryEngine.from_args(base_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94a85854-ca04-41ed-9f44-b6dce1e513e1",
   "metadata": {
    "id": "94a85854-ca04-41ed-9f44-b6dce1e513e1",
    "outputId": "9df10b31-5035-4ada-9a16-71b6e73063e4"
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b334b7b-fcb8-4057-a418-b8d8c425ad14",
   "metadata": {
    "id": "8b334b7b-fcb8-4057-a418-b8d8c425ad14",
    "outputId": "da7e090a-baad-4398-b3dd-9ce92dd4cca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting the amount of safety data used in the RLHF stage could potentially impact the model's performance and generalization capabilities. It may lead to improved safety and robustness of the chat models, as well as influence the fine-tuning process to enhance the overall quality of the models.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c38a124-5279-4a43-a2fe-ed2cbce9bd66",
   "metadata": {
    "id": "1c38a124-5279-4a43-a2fe-ed2cbce9bd66"
   },
   "outputs": [],
   "source": [
    "base_response = base_query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c2910e5-1a45-4de5-8035-5b5a47125d81",
   "metadata": {
    "id": "5c2910e5-1a45-4de5-8035-5b5a47125d81",
    "outputId": "c4936ebf-068e-4bbf-97e0-06701ade526c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting the amount of safety data used in the RLHF stage could potentially lead to improvements in model safety performance without significantly impacting the helpfulness score distribution. It may help the model align with safety guidelines early on, laying a foundation for high-quality human preference data annotation. Additionally, increasing the amount of safety data in model training could result in a significant improvement in the mean safety reward model score while keeping the helpfulness counterpart relatively stable. Furthermore, the addition of more safety training data may gradually eliminate the most unsafe responses, as indicated by the disappearance of the left tail of safety reward model scores.\n"
     ]
    }
   ],
   "source": [
    "print(str(base_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84be450-c036-4cca-bf94-ccfc18e5d52a",
   "metadata": {
    "id": "f84be450-c036-4cca-bf94-ccfc18e5d52a"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "We evaluate how well the hierarchical retriever works compared to the baseline retriever in a more quantitative manner.\n",
    "\n",
    "**WARNING**: This can be *expensive*, especially with GPT-4. Use caution and tune the sample size to fit your budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb5a6511-5756-4cdb-933e-f530f0c40bc3",
   "metadata": {
    "id": "cb5a6511-5756-4cdb-933e-f530f0c40bc3"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n",
    "from llama_index.core.llama_dataset import LabelledRagDataset\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65f1a688-61af-431c-9cc7-16c525106e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4 = OpenAI(model='gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "914e3056-d9e3-42a0-9600-a66ae6a9f075",
   "metadata": {
    "id": "914e3056-d9e3-42a0-9600-a66ae6a9f075"
   },
   "outputs": [],
   "source": [
    "# NOTE: run this if the dataset isn't already saved\n",
    "dataset_generator = RagDatasetGenerator(\n",
    "    root_nodes[:2],\n",
    "    llm=gpt4,\n",
    "    show_progress=True,\n",
    "    num_questions_per_chunk=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9569b69-d9bf-4b85-a1b3-3ff4ef6619b8",
   "metadata": {
    "id": "d9569b69-d9bf-4b85-a1b3-3ff4ef6619b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.36s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.08s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:12<00:00,  4.10s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = await dataset_generator.agenerate_dataset_from_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5b3ba74-0092-4906-88cc-638fa304c97b",
   "metadata": {
    "id": "e5b3ba74-0092-4906-88cc-638fa304c97b"
   },
   "outputs": [],
   "source": [
    "eval_dataset.save_json(\"data/llama2_eval_qr_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87f30894-ba65-4af7-9380-210f6a5b2de4",
   "metadata": {
    "id": "87f30894-ba65-4af7-9380-210f6a5b2de4"
   },
   "outputs": [],
   "source": [
    "# optional\n",
    "eval_dataset = LabelledRagDataset.from_json(\n",
    "    \"data/llama2_eval_qr_dataset.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d793ae5-80be-41ff-8b1f-e92ea27b2a8b",
   "metadata": {
    "id": "2d793ae5-80be-41ff-8b1f-e92ea27b2a8b"
   },
   "source": [
    "### Compare Results\n",
    "\n",
    "We run evaluations on each of the retrievers: correctness, semantic similarity, relevance, and faithfulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90ca35cf-e659-4a1e-8561-d07d50972b3a",
   "metadata": {
    "id": "90ca35cf-e659-4a1e-8561-d07d50972b3a"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6814643-bdb2-47cd-a8a5-69a1bdfdda30",
   "metadata": {
    "id": "f6814643-bdb2-47cd-a8a5-69a1bdfdda30"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    CorrectnessEvaluator,\n",
    "    SemanticSimilarityEvaluator,\n",
    "    RelevancyEvaluator,\n",
    "    FaithfulnessEvaluator,\n",
    "    PairwiseComparisonEvaluator,\n",
    ")\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e71fe3ab-870e-4938-85be-44afdfc1eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4 = OpenAI(temperature=0, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7165362b-801b-4458-9f43-0c14faca2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: can uncomment other evaluators\n",
    "evaluator_c = CorrectnessEvaluator(llm=gpt4)\n",
    "evaluator_s = SemanticSimilarityEvaluator(embed_model=OpenAIEmbedding(model='text-embedding-3-small'))\n",
    "evaluator_r = RelevancyEvaluator(llm=gpt4)\n",
    "evaluator_f = FaithfulnessEvaluator(llm=gpt4)\n",
    "pairwise_evaluator = PairwiseComparisonEvaluator(llm=gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae472816-5927-4f67-9105-fd0ba0c60f49",
   "metadata": {
    "id": "ae472816-5927-4f67-9105-fd0ba0c60f49"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation.eval_utils import get_responses, get_results_df\n",
    "from llama_index.core.evaluation import BatchEvalRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "177803f3-bfa5-455a-bd22-df4dc3baedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_qs = [example.query for example in eval_dataset.examples]\n",
    "ref_response_strs = [example.reference_answer for example in eval_dataset.examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2c5acfa-97ad-4d3a-9dc4-4e25c2c63132",
   "metadata": {
    "id": "a7302e7b-6b3e-4d25-874b-94ffe944b527"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:09<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "pred_responses = get_responses(eval_qs, query_engine, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0bce562f-6c42-446a-b991-f208ca9f55cb",
   "metadata": {
    "id": "0bce562f-6c42-446a-b991-f208ca9f55cb",
    "outputId": "02cc7dce-adc0-4229-edce-ffb7139f9886"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:03<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "base_pred_responses = get_responses(\n",
    "    eval_qs, base_query_engine, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3428afe0-b5e4-4604-b7ce-270f449766cb",
   "metadata": {
    "id": "3428afe0-b5e4-4604-b7ce-270f449766cb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pred_response_strs = [str(p) for p in pred_responses]\n",
    "base_pred_response_strs = [str(p) for p in base_pred_responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0a86029-bf5e-4f26-afdf-a9406bada315",
   "metadata": {
    "id": "b0a86029-bf5e-4f26-afdf-a9406bada315"
   },
   "outputs": [],
   "source": [
    "evaluator_dict = {\n",
    "    \"correctness\": evaluator_c,\n",
    "    \"faithfulness\": evaluator_f,\n",
    "    \"relevancy\": evaluator_r,\n",
    "    \"semantic_similarity\": evaluator_s,\n",
    "}\n",
    "batch_runner = BatchEvalRunner(evaluator_dict, workers=2, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9abccb17-cf7d-4f59-b849-a4d5581df7a9",
   "metadata": {
    "id": "9abccb17-cf7d-4f59-b849-a4d5581df7a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:14<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_results = await batch_runner.aevaluate_responses(\n",
    "    eval_qs, responses=pred_responses, reference=ref_response_strs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c5df1ec-408a-4012-93c7-a0151fa92b9e",
   "metadata": {
    "id": "7c5df1ec-408a-4012-93c7-a0151fa92b9e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:14<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "base_eval_results = await batch_runner.aevaluate_responses(\n",
    "    eval_qs, responses=base_pred_responses, reference=ref_response_strs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "048d0dc0-8080-42d5-8a09-48f8c65abacb",
   "metadata": {
    "id": "ea90f363-71d7-404c-9d4d-f6eea386e59f",
    "outputId": "f105bf85-7fa9-4402-d6e5-327790919652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>correctness</th>\n",
       "      <th>relevancy</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>semantic_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Auto Merging Retriever</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Base Retriever</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.899180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    names  correctness  relevancy  faithfulness  \\\n",
       "0  Auto Merging Retriever          2.5   0.333333           0.0   \n",
       "1          Base Retriever          2.5   0.166667           0.0   \n",
       "\n",
       "   semantic_similarity  \n",
       "0             0.902941  \n",
       "1             0.899180  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = get_results_df(\n",
    "    [eval_results, base_eval_results],\n",
    "    [\"Auto Merging Retriever\", \"Base Retriever\"],\n",
    "    [\"correctness\", \"relevancy\", \"faithfulness\", \"semantic_similarity\"],\n",
    ")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be393093-9a6d-46d1-9d18-d17e92523200",
   "metadata": {
    "id": "be393093-9a6d-46d1-9d18-d17e92523200"
   },
   "source": [
    "**Analysis**: The results are roughly the same.\n",
    "\n",
    "Let's also try to see which answer GPT-4 prefers with our pairwise evals."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/jerryjliu/llama_index/blob/main/docs/examples/retrievers/auto_merging_retriever.ipynb",
     "timestamp": 1702793300147
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
