{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1Y3gSVdHdzb"
   },
   "source": [
    "# Router Query Engine\n",
    "\n",
    "Routers serve as specialized modules designed to process a user's query and select from a set of predefined \"choices,\" characterized by their metadata.\n",
    "\n",
    "There are two primary types of core router modules:\n",
    "\n",
    "1. **LLM Selectors:** These selectors present the available choices as a text prompt, utilizing the LLM text completion endpoint for decision-making.\n",
    "\n",
    "2. **Pydantic Selectors:** Here, choices are passed in the form of Pydantic schemas to a function-calling endpoint. The results are then returned as Pydantic objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pV4KnOmXUPC-"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R_Ttz5WDI8M6"
   },
   "outputs": [],
   "source": [
    "# NOTE: This is ONLY necessary in jupyter notebook.\n",
    "# Details: Jupyter runs an event-loop behind the scenes.\n",
    "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
    "#          This is normally not allowed, we use nest_asyncio to allow it for convenience.\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9454,
     "status": "ok",
     "timestamp": 1698334064081,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "LGEOh3sdFuQ-",
    "outputId": "7be5e69a-c15c-4c5c-ae87-2b5a230fff0d"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Set up the root logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)  # Set logger level to INFO\n",
    "\n",
    "# Clear out any existing handlers\n",
    "logger.handlers = []\n",
    "\n",
    "# Set up the StreamHandler to output to sys.stdout (Colab's output)\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.INFO)  # Set handler level to INFO\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(handler)\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SummaryIndex, SimpleDirectoryReader, StorageContext\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('/home/santhosh/Projects/courses/Pinnacle/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_J2AEezZP4Uf"
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-31 13:43:56--  https://raw.githubusercontent.com/run-llama/llama_index/9607a05a923ddf07deee86a56d386b42943ce381/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‘data/paul_graham/paul_graham_essay.txt’\n",
      "\n",
      "data/paul_graham/pa 100%[===================>]  73.28K  70.8KB/s    in 1.0s    \n",
      "\n",
      "2024-03-31 13:43:58 (70.8 KB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/9607a05a923ddf07deee86a56d386b42943ce381/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f1Awi4MVZRf"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3248,
     "status": "ok",
     "timestamp": 1698334094489,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "TozkIS3mF8DC",
    "outputId": "27a9d1b7-47db-45d7-a67c-09101a6577cd"
   },
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"data/paul_graham\").load_data()\n",
    "\n",
    "nodes = Settings.node_parser.get_nodes_from_documents(documents, chunk_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4LNrmhrK4xe"
   },
   "source": [
    "## Define Summary Index and Vector Index over Same Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = OpenAIEmbedding(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "B9C2Gm1UF8r3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Summary Index for summarization questions\n",
    "summary_index = SummaryIndex(nodes, embed_model=embed_model)\n",
    "\n",
    "# Vector Index for answering specific context questions\n",
    "vector_index = VectorStoreIndex(nodes, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voktqsQNLApj"
   },
   "source": [
    "## Define Query Engines.\n",
    "\n",
    "1. Summary Index Query Engine.\n",
    "2. Vector Index Query Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uLMKbMAUGA9f"
   },
   "outputs": [],
   "source": [
    "# Summary Index Query Engine\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "\n",
    "# Vector Index Query Engine\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzm7L0MzYQUR"
   },
   "source": [
    "## Build summary index and vector index tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fg4aOwPaGNxb"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools.query_engine import QueryEngineTool\n",
    "\n",
    "# Summary Index tool\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=\"Useful for summarization questions related to Paul Graham eassy on What I Worked On.\",\n",
    ")\n",
    "\n",
    "# Vector Index tool\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=\"Useful for retrieving specific context from Paul Graham essay on What I Worked On.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0zHAQS_LF3r"
   },
   "source": [
    "## Define Router Query Engine\n",
    "\n",
    "Various selectors are at your disposal, each offering unique characteristics.\n",
    "\n",
    "Pydantic selectors, supported exclusively by gpt-4-0613 and the default gpt-3.5-turbo-0613, utilize the OpenAI Function Call API. Instead of interpreting raw JSON, they yield pydantic selection objects.\n",
    "\n",
    "On the other hand, LLM selectors employ the LLM to generate a JSON output, which is then parsed to query the relevant indexes.\n",
    "\n",
    "For both selector types, you can opt to route to either a single index or multiple indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTncjEj2LH88"
   },
   "source": [
    "## PydanticSingleSelector\n",
    "\n",
    "Use the OpenAI Function API to generate/parse pydantic objects under the hood for the router selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GGjl2y5QGRcW"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors.llm_selectors import LLMSingleSelector, LLMMultiSelector\n",
    "from llama_index.core.selectors.pydantic_selectors import PydanticMultiSelector, PydanticSingleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Router Query Engine\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=PydanticSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11130,
     "status": "ok",
     "timestamp": 1698334234628,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "0hywia-DGTx2",
    "outputId": "3810695c-327b-4b3c-fea9-def722100d8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Selecting query engine 0: The choice is specifically focused on summarization questions related to Paul Graham's essay on What I Worked On..\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1698334241283,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "sriu-0zoLR7q",
    "outputId": "88cab857-1e95-4eaf-d119-cee06013892d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:14px\">The document provides a detailed account of the author's journey through various phases of his life, starting from his early experiences with writing and programming, his exploration of artificial intelligence (AI) and eventual transition into the field of art, to his involvement in the early days of the World Wide Web, founding Viaweb, and the eventual creation of Y Combinator. It highlights themes of self-directed learning, financial concerns, the evolving landscape of technology and art, the challenges and successes in startups, and the author's evolving interests and projects over the years. The narrative showcases Paul Graham's commitment to pursuing new challenges, learning experiences, and his reflections on work, creativity, and the impact of unprestigious pursuits.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(f'<p style=\"font-size:14px\">{response.response}</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zkEOzNYLUQ_"
   },
   "source": [
    "## LLMSingleSelector\n",
    "\n",
    "Utilize OpenAI (or another LLM) to internally interpret the generated JSON and determine a sub-index for routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "S6i5dK4Muuaz"
   },
   "outputs": [],
   "source": [
    "# Create Router Query Engine\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10361,
     "status": "ok",
     "timestamp": 1698336346707,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "_y-1ztZ6utGp",
    "outputId": "5bc8a8d9-8a6d-408e-a63a-ae1bbc445b97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Selecting query engine 0: The summary of the document would be best captured by summarization questions related to Paul Graham's essay on What I Worked On..\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1698336350750,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "vwgHKW-qusYR",
    "outputId": "130038dc-a965-4dc2-e793-7e0487fedcb1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:14px\">The document provides a detailed account of the author's journey from his early experiences with writing and programming to his exploration of artificial intelligence, his disillusionment with traditional AI approaches, his fascination with Lisp hacking, and his eventual transition into the world of art. It describes his struggles and decisions regarding his academic path, including his time in a PhD program in computer science, his interest in art classes, and his eventual pursuit of art education at RISD. The narrative also touches on his experiences with applying to art schools, particularly the Accademia di Belli Arti in Florence, and the challenges he faced during the entrance exam process. The author reflects on the lack of substantial learning experiences at art institutions, his entrepreneurial journey with Viaweb, the acquisition by Yahoo, his decision to return to painting, the creation of a new company, struggles with running a company, involvement in Y Combinator, personal challenges, and the development of new ideas and projects. The narrative culminates in a focus on writing essays, advocating for changes in venture capital practices, and a discussion on invented vs discovered knowledge.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(f'<p style=\"font-size:14px\">{response.response}</p>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4036,
     "status": "ok",
     "timestamp": 1698336369564,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "rMgPIzfvuriI",
    "outputId": "22ea75dc-dc00-4482-af00-d972f67deeb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Selecting query engine 1: Useful for retrieving specific context from Paul Graham essay on What I Worked On..\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What did Paul Graham do after RICS?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1698336376616,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "Bzo6X5W2uqpe",
    "outputId": "c1e75d00-d12d-4441-e046-1a329aea2d23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:14px\">After RISD, Paul Graham went back to the US and decided to get a job for a year at a company called Interleaf, which specialized in creating software for documents, similar to Microsoft Word.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(f'<p style=\"font-size:14px\">{response.response}</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MqCihafLZyE"
   },
   "source": [
    "## PydanticMultiSelector\n",
    "\n",
    "If you anticipate queries being directed to multiple indexes, it's advisable to use a multi-selector. This selector dispatches the query to various sub-indexes and subsequently aggregates the responses through a summary index to deliver a comprehensive answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEV_L_mkWL7V"
   },
   "source": [
    "## Let's create a simplekeywordtable index and corresponding tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Hexv6i0runj8"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleKeywordTableIndex\n",
    "\n",
    "keyword_index = SimpleKeywordTableIndex(nodes)\n",
    "\n",
    "keyword_query_engine = keyword_index.as_query_engine()\n",
    "\n",
    "keyword_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=keyword_query_engine,\n",
    "    description=\"Useful for retrieving specific context using keywords from Paul Graham essay on What I Worked On.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBLyUgEYWTcc"
   },
   "source": [
    "## Build a router query engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "as9REJo7ulzu"
   },
   "outputs": [],
   "source": [
    "query_engine = RouterQueryEngine(\n",
    "    selector=PydanticMultiSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        vector_tool,\n",
    "        keyword_tool,\n",
    "        summary_tool\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "HDIFO7v9uixW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Selecting query engine 0: This choice is useful for retrieving specific context from the Paul Graham essay on What I Worked On, which can help in identifying notable events and people from the author's time at Interleaf and YC..\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Selecting query engine 1: This choice is useful for retrieving specific context using keywords from the Paul Graham essay on What I Worked On, which can aid in identifying notable events and people from the author's time at Interleaf and YC..\n",
      "> Starting query: What were noteable events and people from the authors time at Interleaf and YC?\n",
      "query keywords: ['people', 'noteable', 'events', 'interleaf', 'authors', 'time', 'yc']\n",
      "> Extracted keywords: ['people', 'interleaf', 'time', 'yc']\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Combining responses from multiple query engines.\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# This query could use either a keyword or vector query engine, so it will combine responses from both\n",
    "response = query_engine.query(\n",
    "    \"What were noteable events and people from the authors time at Interleaf and YC?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "EuI1xYLN-rKe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:14px\">The notable events and people from the author's time at Interleaf and Y Combinator (YC) include dealing with the stress caused by Hacker News (HN) while running YC, the growth and scaling of YC as a startup funding platform, the creation of Hacker News as a news aggregator for startup founders, the challenges faced by founders and the sense of community among YC alumni, the decision to invest $6k per founder in return for 6% equity, the renaming of Y Combinator from Cambridge Seed, the close working relationship with Jessica Livingston during the early days of YC, working on software for creating documents at Interleaf, learning about the dynamics between low-end and high-end software, the challenges of working with a scripting language based on Lisp, helping startups with their varied problems at Y Combinator, receiving unsolicited advice from Robert Morris to ensure Y Combinator wasn't the last cool thing the author did, and eventually deciding to hand over YC to someone else due to personal reasons.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(f'<p style=\"font-size:14px\">{response.response}</p>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1T71Oegv2f9uR7pFkOWcFX9NxL6S3d2En",
     "timestamp": 1702791935731
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
