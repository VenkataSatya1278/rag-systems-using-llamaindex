{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYkWSVQDPckV"
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "Evaluation and benchmarking play a pivotal role in the development of LLM Applications. For optimizing the performance of applications such as RAG (Retrieval Augmented Generation), a robust measurement mechanism is indispensable.\n",
    "\n",
    "LlamaIndex offers vital modules tailored to assess the quality of generated outputs. Additionally, it incorporates specialized modules designed specifically to evaluate content retrieval quality. LlamaIndex categorizes its evaluation into two primary types:\n",
    "\n",
    "*   **Response Evaluation**\n",
    "*   **Retrieval Evaluation**\n",
    "\n",
    "[Documentation\n",
    "](https://gpt-index.readthedocs.io/en/latest/core_modules/supporting_modules/evaluation/root.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTMyT_qQSH0L"
   },
   "source": [
    "# Response Evaluation\n",
    "\n",
    "Evaluating results from LLMs is distinct from traditional machine learning's straightforward outcomes. LlamaIndex employs evaluation modules, using a benchmark LLM like GPT-4, to gauge answer accuracy. Notably, these modules often blend query, context, and response, minimizing the need for ground-truth labels.\n",
    "\n",
    "The evaluation modules manifest in the following categories:\n",
    "\n",
    "*   **Faithfulness:** Assesses whether the response remains true to the retrieved contexts, ensuring there's no distortion or \"hallucination.\"\n",
    "*   **Context Relevancy:** Evaluates the relevance of both the retrieved context and the generated answer to the initial query.\n",
    "*   **Correctness:** Determines if the generated answer aligns with the reference answer based on the query (this does require labels).\n",
    "\n",
    "Furthermore, LlamaIndex has the capability to autonomously generate questions from your data, paving the way for an evaluation pipeline to assess the RAG application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Evaluation of RAG can be costly GPT-4 is being used. Please keep track of the cost. You can try to run on lesser data to reduce cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1703533305432,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "4fTQJZDiZtIR"
   },
   "outputs": [],
   "source": [
    "# attach to the same event-loop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Set up the root logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)  # Set logger level to INFO\n",
    "\n",
    "# Clear out any existing handlers\n",
    "logger.handlers = []\n",
    "\n",
    "# Set up the StreamHandler to output to sys.stdout (Colab's output)\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.INFO)  # Set handler level to INFO\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3898,
     "status": "ok",
     "timestamp": 1703533309324,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "O384ocD_OjDG",
    "outputId": "edf1b8d5-00c3-42bc-dbf2-b3bc0bb6da88",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    Response,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    "    CorrectnessEvaluator,\n",
    "    RetrieverEvaluator,\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cKlax-updNW-"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "# load_dotenv('D:/.env')\n",
    "# OPENAI_API_KEY = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('D:/Training/FAA-Training/Beyond-the-Prompt-Practical-RAG-for-Real-World-AI/RAG-systems-using-LlamaIndex/RAG-System-Using-LamaIndex/.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CChQ98mgWGcC"
   },
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 775,
     "status": "ok",
     "timestamp": 1703533310092,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "7smekBCXWS3X",
    "outputId": "8b04510c-e58b-481f-8f64-8076330628d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "'data/paul_graham/paul_graham_essay.txt': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/9607a05a923ddf07deee86a56d386b42943ce381/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNfuJB0xXKw8"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1703533310092,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "hIz7x-91VyuY"
   },
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(\"./data/paul_graham/\")\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVy40TPDXQLN"
   },
   "source": [
    "### Generate Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4iCdPoP8XMY6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_generator = RagDatasetGenerator.from_documents(documents, llm=OpenAI(temperature=0, model=\"gpt-4o-mini\"),\n",
    "                                                   num_questions_per_chunk=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = data_generator.generate_dataset_from_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Describe the author's early experiences with programming on the IBM 1401. What challenges did he face, and how did these experiences shape his understanding of programming at that time?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset.examples[0].query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The author\\'s early experiences with programming on the IBM 1401 were marked by curiosity and confusion. He began programming at the age of 13 or 14, using an early version of Fortran on a machine that was part of his school district\\'s data processing resources. The IBM 1401 was a complex system for him, resembling a \"mini Bond villain\\'s lair\" with its array of alien-looking machines. \\n\\nOne of the main challenges he faced was the limitation of input methods; the only way to input data into the programs was through punched cards, and he did not have any data stored in that format. This lack of input options severely restricted what he could accomplish with the machine. He also struggled with the mathematical knowledge required to create interesting programs, which left him feeling puzzled about how to effectively use the computer. \\n\\nHis most memorable experience was realizing that programs could run indefinitely without terminating, which was a significant moment for him, highlighting both a technical and social error in a non-time-sharing environment. This experience underscored the limitations of the IBM 1401 and contributed to his understanding of programming as a challenging and somewhat inaccessible field at that time. \\n\\nOverall, these early experiences shaped his perception of programming as something that was not only technically demanding but also constrained by the technology of the era, leading him to later embrace the more interactive and accessible nature of microcomputers.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset.examples[0].reference_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = [example.query for example in eval_dataset.examples]\n",
    "eval_answers = [example.reference_answer for example in eval_dataset.examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533588728,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "G1gDWlUxjooJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533588728,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "_HeCZJ1xYKYH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Describe the author's early experiences with programming on the IBM 1401. What challenges did he face, and how did these experiences shape his understanding of programming at that time?\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1703533588728,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "47guGTdTYOEi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The author\\'s early experiences with programming on the IBM 1401 were marked by curiosity and confusion. He began programming at the age of 13 or 14, using an early version of Fortran on a machine that was part of his school district\\'s data processing resources. The IBM 1401 was a complex system for him, resembling a \"mini Bond villain\\'s lair\" with its array of alien-looking machines. \\n\\nOne of the main challenges he faced was the limitation of input methods; the only way to input data into the programs was through punched cards, and he did not have any data stored in that format. This lack of input options severely restricted what he could accomplish with the machine. He also struggled with the mathematical knowledge required to create interesting programs, which left him feeling puzzled about how to effectively use the computer. \\n\\nHis most memorable experience was realizing that programs could run indefinitely without terminating, which was a significant moment for him, highlighting both a technical and social error in a non-time-sharing environment. This experience underscored the limitations of the IBM 1401 and contributed to his understanding of programming as a challenging and somewhat inaccessible field at that time. \\n\\nOverall, these early experiences shaped his perception of programming as something that was not only technically demanding but also constrained by the technology of the era, leading him to later embrace the more interactive and accessible nature of microcomputers.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_answers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCNyxGNYgaxl"
   },
   "source": [
    "To be consistent we will fix evaluation query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533588729,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "AABMc2Uxgew_"
   },
   "outputs": [],
   "source": [
    "eval_query = eval_questions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Check https://openai.com/pricing to select the less costlier variant of an LLM.<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533588729,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "2XFysSdSX7pS"
   },
   "outputs": [],
   "source": [
    "# Fix gpt-4o-mini LLM for generating response\n",
    "gpt4o_mini = OpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "\n",
    "# Fix GPT-4o LLM for evaluation\n",
    "gpt4 = OpenAI(temperature=0, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533588729,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "DWLP0Rk8Yj5O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# create vector index\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents, llm=OpenAI(temperature=0, model=\"gpt-4o\")\n",
    ")\n",
    "\n",
    "# Query engine to generate response\n",
    "query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533588729,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "fzOT-SiFsABn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "retriever = vector_index.as_retriever(similarity_top_k=3)\n",
    "nodes = retriever.retrieve(eval_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1703533588729,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "lB9nry-UsMeR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:14px\">It felt like I was doing life right. I remember that because I was slightly dismayed at how novel it felt. The good news is that I had more moments like this over the next few years.\n",
       "\n",
       "In the summer of 2016 we moved to England. We wanted our kids to see what it was like living in another country, and since I was a British citizen by birth, that seemed the obvious choice. We only meant to stay for a year, but we liked it so much that we still live there. So most of Bel was written in England.\n",
       "\n",
       "In the fall of 2019, Bel was finally finished. Like McCarthy's original Lisp, it's a spec rather than an implementation, although like McCarthy's Lisp it's a spec expressed as code.\n",
       "\n",
       "Now that I could write essays again, I wrote a bunch about topics I'd had stacked up. I kept writing essays through 2020, but I also started to think about other things I could work on. How should I choose what to do? Well, how had I chosen what to work on in the past? I wrote an essay for myself to answer that question, and I was surprised how long and messy the answer turned out to be. If this surprised me, who'd lived it, then I thought perhaps it would be interesting to other people, and encouraging to those with similarly messy lives. So I wrote a more detailed version for others to read, and this is the last sentence of it.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Notes\n",
       "\n",
       "[1] My experience skipped a step in the evolution of computers: time-sharing machines with interactive OSes. I went straight from batch processing to microcomputers, which made microcomputers seem all the more exciting.\n",
       "\n",
       "[2] Italian words for abstract concepts can nearly always be predicted from their English cognates (except for occasional traps like polluzione). It's the everyday words that differ. So if you string together a lot of abstract concepts with a few simple verbs, you can make a little Italian go a long way.\n",
       "\n",
       "[3] I lived at Piazza San Felice 4, so my walk to the Accademia went straight down the spine of old Florence: past the Pitti, across the bridge, past Orsanmichele, between the Duomo and the Baptistery, and then up Via Ricasoli to Piazza San Marco. I saw Florence at street level in every possible condition, from empty dark winter evenings to sweltering summer days when the streets were packed with tourists.\n",
       "\n",
       "[4] You can of course paint people like still lives if you want to, and they're willing. That sort of portrait is arguably the apex of still life painting, though the long sitting does tend to produce pained expressions in the sitters.\n",
       "\n",
       "[5] Interleaf was one of many companies that had smart people and built impressive technology, and yet got crushed by Moore's Law. In the 1990s the exponential growth in the power of commodity (i.e. Intel) processors rolled up high-end, special-purpose hardware and software companies like a bulldozer.\n",
       "\n",
       "[6] The signature style seekers at RISD weren't specifically mercenary. In the art world, money and coolness are tightly coupled. Anything expensive comes to be seen as cool, and anything seen as cool will soon become equally expensive.\n",
       "\n",
       "[7] Technically the apartment wasn't rent-controlled but rent-stabilized, but this is a refinement only New Yorkers would know or care about. The point is that it was really cheap, less than half market price.\n",
       "\n",
       "[8] Most software you can launch as soon as it's done. But when the software is an online store builder and you're hosting the stores, if you don't have any users yet, that fact will be painfully obvious. So before we could launch publicly we had to launch privately, in the sense of recruiting an initial set of users and making sure they had decent-looking stores.\n",
       "\n",
       "[9] We'd had a code editor in Viaweb for users to define their own page styles. They didn't know it, but they were editing Lisp expressions underneath. But this wasn't an app editor, because the code ran when the merchants' sites were generated, not when shoppers visited them.\n",
       "\n",
       "[10] This was the first instance of what is now a familiar experience, and so was what happened next, when I read the comments and found they were full of angry people. How could I claim that Lisp was better than other languages? Weren't they all Turing complete?</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(f'<p style=\"font-size:14px\">{nodes[1].get_text()}</p>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gs6eBCIX2yM"
   },
   "source": [
    "## Context Relevency Evaluation\n",
    "\n",
    "Measures if the response + source nodes match the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1703533588729,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "jfTwgJ5SXoeB"
   },
   "outputs": [],
   "source": [
    "# Create RelevancyEvaluator using GPT-4 LLM\n",
    "relevancy_evaluator = RelevancyEvaluator(llm=gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533588730,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "6Bw9KWY-YflD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Generate response\n",
    "response_vector = query_engine.query(eval_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The author's early experiences with programming on the IBM 1401 involved using an early version of Fortran where programs had to be typed on punch cards. He faced challenges due to the limited input options, as the only form of input was data stored on punched cards. This limitation meant he struggled to find meaningful tasks to perform with the computer. These experiences likely shaped his understanding of programming at that time by highlighting the importance of having accessible and interactive computing systems, as opposed to the batch processing method he encountered with the IBM 1401.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_vector.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Source (Doc id: f99f1820-f485-416f-b3d6-29c1c5e95b70): What I Worked On\n",
      "\n",
      "February 2021\n",
      "\n",
      "Before college the two main things I worked on, outside of schoo...\n",
      "\n",
      "> Source (Doc id: dc6c5486-005b-4d03-bb0b-39b0f81a4346): It felt like I was doing life right. I remember that because I was slightly dismayed at how novel...\n"
     ]
    }
   ],
   "source": [
    "print(response_vector.get_formatted_sources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533588730,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "6Bw9KWY-YflD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "eval_result = relevancy_evaluator.evaluate_response(query=eval_query, response=response_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533588730,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "3JMGtE-JaQWd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Describe the author's early experiences with programming on the IBM 1401. What challenges did he face, and how did these experiences shape his understanding of programming at that time?\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533588730,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "3irb7WZ-cW84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The author's early experiences with programming on the IBM 1401 involved using an early version of Fortran where programs had to be typed on punch cards. He faced challenges due to the limited input options, as the only form of input was data stored on punched cards. This limitation meant he struggled to find meaningful tasks to perform with the computer. These experiences likely shaped his understanding of programming at that time by highlighting the importance of having accessible and interactive computing systems, as opposed to the batch processing method he encountered with the IBM 1401.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1703533588730,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "GBFxnKgXcZlT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaDtmBEjhGQ8"
   },
   "source": [
    "Relevancy evaluation with multiple source nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 313968,
     "status": "aborted",
     "timestamp": 1703533588731,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "QOhxXsMIgVH8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Retrying request to /chat/completions in 0.406157 seconds\n",
      "Retrying request to /chat/completions in 0.406157 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Retrying request to /chat/completions in 0.416058 seconds\n",
      "Retrying request to /chat/completions in 0.416058 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Retrying request to /chat/completions in 0.396580 seconds\n",
      "Retrying request to /chat/completions in 0.396580 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Create Query Engine with similarity_top_k=3\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "# Create response\n",
    "response_vector = query_engine.query(eval_query)\n",
    "\n",
    "# Evaluate with each source node\n",
    "eval_source_result_full = [\n",
    "    relevancy_evaluator.evaluate(\n",
    "        query=eval_query,\n",
    "        response=response_vector.response,\n",
    "        contexts=[source_node.get_content()],\n",
    "    )\n",
    "    for source_node in response_vector.source_nodes\n",
    "]\n",
    "\n",
    "# Evaluation result\n",
    "eval_source_result = [\n",
    "    \"Pass\" if result.passing else \"Fail\" for result in eval_source_result_full\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 313966,
     "status": "aborted",
     "timestamp": 1703533588731,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "-euW1W3VhgPx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pass', 'Fail', 'Fail']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_source_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rrd_7kufgozj"
   },
   "source": [
    "## Faithfullness Evaluator\n",
    "\n",
    " Measures if the response from a query engine matches any source nodes. This is useful for measuring if the response was hallucinated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 313966,
     "status": "aborted",
     "timestamp": 1703533588731,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "Pb3d08hrclbA"
   },
   "outputs": [],
   "source": [
    "faithfulness_evaluator = FaithfulnessEvaluator(llm=gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 313963,
     "status": "aborted",
     "timestamp": 1703533588731,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "hWOKhDVTdm5q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying request to /chat/completions in 0.431573 seconds\n",
      "Retrying request to /chat/completions in 0.431573 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "eval_result = faithfulness_evaluator.evaluate_response(response=response_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 313961,
     "status": "aborted",
     "timestamp": 1703533588731,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "yH977tlPk6HQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YES'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 313960,
     "status": "aborted",
     "timestamp": 1703533588731,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "nsiWpNXHdsoz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 313959,
     "status": "aborted",
     "timestamp": 1703533588732,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "JLdKEvMefTIO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqsEWzF1i1Rk"
   },
   "source": [
    "## Correctness Evaluator\n",
    "\n",
    "Evaluates the relevance and correctness of a generated answer against a reference answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 313959,
     "status": "aborted",
     "timestamp": 1703533588732,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "ZdX4-K-NfNIh"
   },
   "outputs": [],
   "source": [
    "correctness_evaluator = CorrectnessEvaluator(llm=gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 313956,
     "status": "aborted",
     "timestamp": 1703533588732,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "6fOKYRacjIkm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying request to /chat/completions in 0.376393 seconds\n",
      "Retrying request to /chat/completions in 0.376393 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "eval_reference_answer = eval_answers[0]\n",
    "\n",
    "correctness_result = correctness_evaluator.evaluate(\n",
    "    query=eval_query,\n",
    "    response=response_vector.response,\n",
    "    reference=eval_reference_answer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 313955,
     "status": "aborted",
     "timestamp": 1703533588732,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "BbWAp_krjSCI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctness_result.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 313953,
     "status": "aborted",
     "timestamp": 1703533588732,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "qBk5I1i9jWM_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctness_result.passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 313952,
     "status": "aborted",
     "timestamp": 1703533588733,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "66aEQczhjXpO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The generated answer is relevant and mostly correct, capturing the essence of the author's early experiences with the IBM 1401, including the use of punch cards and the challenges faced. However, it lacks some specific details present in the reference answer, such as the author's age, the description of the IBM 1401, and the impact of these experiences on his later embrace of microcomputers.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctness_result.feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcEM9N4HRjHf"
   },
   "source": [
    "## BatchEvalRunner - Run Evaluations in batch manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533589254,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "SFK9CyRGQ5cH",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Retrying request to /chat/completions in 0.485914 seconds\n",
      "Retrying request to /chat/completions in 0.485914 seconds\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.evaluation import BatchEvalRunner\n",
    "\n",
    "runner = BatchEvalRunner(\n",
    "    {\n",
    "     \"faithfulness\": faithfulness_evaluator,\n",
    "     \"relevancy\": relevancy_evaluator,\n",
    "     \"correctness\": correctness_evaluator\n",
    "     },\n",
    "    workers=8,\n",
    ")\n",
    "\n",
    "eval_results = await runner.aevaluate_queries(\n",
    "    query_engine, queries=eval_questions, reference = eval_answers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533589254,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "JJ0ObJrmQ97A"
   },
   "outputs": [],
   "source": [
    "def get_eval_results(key, eval_results):\n",
    "    results = eval_results[key]\n",
    "    correct = 0\n",
    "    for result in results:\n",
    "        if result.passing:\n",
    "            correct += 1\n",
    "    score = correct / len(results)\n",
    "    print(f\"{key} Score: {score}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533589254,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "i4UxjfvWQ_9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness Score: 0.9565217391304348\n"
     ]
    }
   ],
   "source": [
    "_ = get_eval_results(\"faithfulness\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533589255,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "Qu-6-JV5RDX3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevancy Score: 0.9130434782608695\n"
     ]
    }
   ],
   "source": [
    "_ = get_eval_results(\"relevancy\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533589255,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "IHWJi1S3ZNUm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correctness Score: 0.8913043478260869\n"
     ]
    }
   ],
   "source": [
    "_ = get_eval_results(\"correctness\", eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQUFlSGmRMKm"
   },
   "source": [
    "## Benchmark using [LlamaDatasets](https://llamahub.ai/?tab=llama_datasets).\n",
    "\n",
    "It's a 3 step process:\n",
    "\n",
    "1. Download dataset\n",
    "2. Build your RAG Pipeline\n",
    "3. Evaluate using RagEvaluatorPack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\module4-evaluation-of-rag-systems\\rag_evaluator_pack\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-packs-rag-evaluator==0.4.0) (0.5.0)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.6,>=0.5.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-packs-rag-evaluator==0.4.0) (0.5.4)\n",
      "Requirement already satisfied: pandas in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-packs-rag-evaluator==0.4.0) (2.2.3)\n",
      "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (0.13.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.102.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pandas->llama-index-packs-rag-evaluator==0.4.0) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pandas->llama-index-packs-rag-evaluator==0.4.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pandas->llama-index-packs-rag-evaluator==0.4.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pandas->llama-index-packs-rag-evaluator==0.4.0) (2025.2)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (3.12.15)\n",
      "Requirement already satisfied: aiosqlite in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (2025.7.0)\n",
      "Requirement already satisfied: httpx in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.3.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (3.9.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (11.3.0)\n",
      "Requirement already satisfied: platformdirs in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (4.4.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (2.0.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (0.11.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (4.14.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (0.9.0)\n",
      "Requirement already satisfied: wrapt in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.17.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-packs-rag-evaluator==0.4.0) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (3.10)\n",
      "Requirement already satisfied: griffe in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.13.0)\n",
      "Requirement already satisfied: jinja2 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (3.1.6)\n",
      "Requirement already satisfied: certifi in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (0.16.0)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (0.4.0)\n",
      "Requirement already satisfied: click in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (8.2.1)\n",
      "Requirement already satisfied: joblib in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (2025.7.34)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (3.2.4)\n",
      "Requirement already satisfied: colorama in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (24.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index-packs-rag-evaluator==0.4.0) (3.0.2)\n",
      "Building wheels for collected packages: llama-index-packs-rag-evaluator\n",
      "  Building wheel for llama-index-packs-rag-evaluator (pyproject.toml): started\n",
      "  Building wheel for llama-index-packs-rag-evaluator (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for llama-index-packs-rag-evaluator: filename=llama_index_packs_rag_evaluator-0.4.0-py3-none-any.whl size=4950 sha256=d38851c41376c4455a264bca29c4db29e7bbd2faccbe9506f1f38319d0d676d3\n",
      "  Stored in directory: C:\\Users\\venkatasp\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-25_m068c\\wheels\\2a\\78\\25\\fe677ad6fa541058c524dae96438c08439e6c76c5a7e8a5fd5\n",
      "Successfully built llama-index-packs-rag-evaluator\n",
      "Installing collected packages: llama-index-packs-rag-evaluator\n",
      "Successfully installed llama-index-packs-rag-evaluator-0.4.0\n",
      "Successfully downloaded RagEvaluatorPack to ./rag_evaluator_pack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!llamaindex-cli download-llamapack RagEvaluatorPack --download-dir ./rag_evaluator_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset import LabelledRagDataset\n",
    "from llama_index.packs.rag_evaluator import RagEvaluatorPack\n",
    "from llama_index.core.llama_pack import download_llama_pack\n",
    "from llama_index.core import VectorStoreIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the required files from the below link and move them to the folders mentioned below in the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/run-llama/llama-datasets/tree/main/llama_datasets/paul_graham_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset = LabelledRagDataset.from_json(\"./data/rag_dataset.json\")\n",
    "documents = SimpleDirectoryReader(input_dir=\"./data/source_files\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the key issues preventing the wide ad...</td>\n",
       "      <td>[From Bitcoin to Solana – Innovating Blockchai...</td>\n",
       "      <td>The key issues preventing the wide adoption of...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does blockchain technology provide data se...</td>\n",
       "      <td>[From Bitcoin to Solana – Innovating Blockchai...</td>\n",
       "      <td>Blockchain technology provides data security a...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the projected growth rate of the block...</td>\n",
       "      <td>[2 \\n \\nchain market size is expected to grow ...</td>\n",
       "      <td>The projected growth rate of the blockchain ma...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are some of the challenges facing enterpr...</td>\n",
       "      <td>[2 \\n \\nchain market size is expected to grow ...</td>\n",
       "      <td>Some of the challenges facing enterprise adopt...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the key issues that need to be addres...</td>\n",
       "      <td>[3 \\n \\nScalability.  Scalability  is the seco...</td>\n",
       "      <td>The key issues that need to be addressed in or...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How can blockchains enhance security and integ...</td>\n",
       "      <td>[3 \\n \\nScalability.  Scalability  is the seco...</td>\n",
       "      <td>Blockchains can enhance security and integrity...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does Solana's blockchain technology addres...</td>\n",
       "      <td>[4 \\n \\ntionary nature of blockchain technolog...</td>\n",
       "      <td>Solana's blockchain technology addresses criti...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explain the main data structure of a blockchai...</td>\n",
       "      <td>[4 \\n \\ntionary nature of blockchain technolog...</td>\n",
       "      <td>The main data structure of a blockchain is a c...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Explain the structure of the main body of each...</td>\n",
       "      <td>[5 \\n \\nTX Counter\\nTX TX TXprevious block \\nh...</td>\n",
       "      <td>The main body of each block in the blockchain ...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Discuss the role and significance of smart con...</td>\n",
       "      <td>[5 \\n \\nTX Counter\\nTX TX TXprevious block \\nh...</td>\n",
       "      <td>Smart contracts play a crucial role in a block...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What are the two core proof-based algorithms m...</td>\n",
       "      <td>[6 \\n \\nConsensus issues . The c onsensus algo...</td>\n",
       "      <td>The two core proof-based algorithms mentioned ...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What are the performance and scalability issue...</td>\n",
       "      <td>[6 \\n \\nConsensus issues . The c onsensus algo...</td>\n",
       "      <td>The performance issues faced by typical blockc...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What are the advantages and disadvantages of p...</td>\n",
       "      <td>[7 \\n \\nMany other issues also impact the matu...</td>\n",
       "      <td>The advantages of permissionless blockchains a...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Can you provide examples of different types of...</td>\n",
       "      <td>[7 \\n \\nMany other issues also impact the matu...</td>\n",
       "      <td>Examples of different types of blockchain plat...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What are the main differences between public a...</td>\n",
       "      <td>[8 \\n \\n  Ethereum  Hyperledger ： \\nGeneral op...</td>\n",
       "      <td>The main differences between public and privat...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Why did the author choose six specific blockch...</td>\n",
       "      <td>[8 \\n \\n  Ethereum  Hyperledger ： \\nGeneral op...</td>\n",
       "      <td>The author chose six specific blockchain platf...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What are the main differences between public b...</td>\n",
       "      <td>[9 \\n \\nblockchain structures and algorithms c...</td>\n",
       "      <td>The main differences between public blockchain...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How does Solana differentiate itself from othe...</td>\n",
       "      <td>[9 \\n \\nblockchain structures and algorithms c...</td>\n",
       "      <td>Solana differentiates itself from other blockc...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How does Bitcoin's concept of \"wallet address\"...</td>\n",
       "      <td>[10 \\n \\n3 Analysis of the Selected Main Frame...</td>\n",
       "      <td>Bitcoin's concept of \"wallet address\" differs ...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What is the potential drawback of Bitcoin's tr...</td>\n",
       "      <td>[10 \\n \\n3 Analysis of the Selected Main Frame...</td>\n",
       "      <td>The potential drawback of Bitcoin's transactio...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explain the concept of smart contracts in Ethe...</td>\n",
       "      <td>[11 \\n \\nThis case above  is only a one -trans...</td>\n",
       "      <td>In Ethereum, smart contracts are a key concept...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>In the context of Bitcoin, what are the potent...</td>\n",
       "      <td>[11 \\n \\nThis case above  is only a one -trans...</td>\n",
       "      <td>In the context of Bitcoin, there are up to 5 p...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What are the three types of transactions in Et...</td>\n",
       "      <td>[12 \\n \\nof users, can be digitalized. This om...</td>\n",
       "      <td>The three types of transactions in Ethereum ar...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>How does Gas play a role in Ethereum transacti...</td>\n",
       "      <td>[12 \\n \\nof users, can be digitalized. This om...</td>\n",
       "      <td>Gas plays a role in Ethereum transactions by r...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What are the three main features of EOS mentio...</td>\n",
       "      <td>[13 \\n \\n EOS provides not only tools for DApp...</td>\n",
       "      <td>The three main features of EOS mentioned in th...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Why was the number 21 chosen for the selected ...</td>\n",
       "      <td>[13 \\n \\n EOS provides not only tools for DApp...</td>\n",
       "      <td>The number 21 was chosen for the selected bloc...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What is the purpose of the rotation mechanism ...</td>\n",
       "      <td>[14 \\n \\n21 selected block producers\\nConsensu...</td>\n",
       "      <td>The purpose of the rotation mechanism in the s...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>How does Hyperledger Fabric differ from tradit...</td>\n",
       "      <td>[14 \\n \\n21 selected block producers\\nConsensu...</td>\n",
       "      <td>Hyperledger Fabric differs from traditional bl...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What are the three main components in Hyperled...</td>\n",
       "      <td>[15 \\n \\nFig. 9. Hyperledger Fabric Architectu...</td>\n",
       "      <td>The three main components in Hyperledger Fabri...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>How does the \"execute-order-validate\" mechanis...</td>\n",
       "      <td>[15 \\n \\nFig. 9. Hyperledger Fabric Architectu...</td>\n",
       "      <td>The \"execute-order-validate\" mechanism in Hype...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>How does Hyperledger Fabric ensure confidentia...</td>\n",
       "      <td>[16 \\n \\nAnother  attractive attribute of Fabr...</td>\n",
       "      <td>Hyperledger Fabric ensures confidentiality in ...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>What are the two types of membership in Corda ...</td>\n",
       "      <td>[16 \\n \\nAnother  attractive attribute of Fabr...</td>\n",
       "      <td>The two types of membership in Corda are worki...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>What are the three types of notary service mod...</td>\n",
       "      <td>[17 \\n \\nWorking node\\nNotary serviceNotary Da...</td>\n",
       "      <td>The three types of notary service models in Co...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>How does the DAG (Directed Acyclic Graph) syst...</td>\n",
       "      <td>[17 \\n \\nWorking node\\nNotary serviceNotary Da...</td>\n",
       "      <td>The DAG system improves the TPS of a blockchai...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Explain the concept of Proof of History in the...</td>\n",
       "      <td>[18 \\n \\nbecause DAG system needn’t to synchro...</td>\n",
       "      <td>Proof of History is a mechanism used in the So...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>How does the DAG (Directed Acyclic Graph) data...</td>\n",
       "      <td>[18 \\n \\nbecause DAG system needn’t to synchro...</td>\n",
       "      <td>The DAG (Directed Acyclic Graph) data structur...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>How does Solana handle the synchronization of ...</td>\n",
       "      <td>[19 \\n \\nFig. 14. Components of Solana  \\nThen...</td>\n",
       "      <td>Solana handles the synchronization of transact...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Why is it important for organizations to caref...</td>\n",
       "      <td>[19 \\n \\nFig. 14. Components of Solana  \\nThen...</td>\n",
       "      <td>It is important for organizations to carefully...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>What are the critical issues that enterprises ...</td>\n",
       "      <td>[20 \\n \\nBusiness Model drives the solution. B...</td>\n",
       "      <td>The critical issues that enterprises should co...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>How do performance and scalability factors lim...</td>\n",
       "      <td>[20 \\n \\nBusiness Model drives the solution. B...</td>\n",
       "      <td>Performance and scalability factors limit the ...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>How can innovative data structures and algorit...</td>\n",
       "      <td>[21 \\n \\nthe original Bitcoin and Ethereaum by...</td>\n",
       "      <td>Innovative data structures and algorithms can ...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>What are some key issues related to data gover...</td>\n",
       "      <td>[21 \\n \\nthe original Bitcoin and Ethereaum by...</td>\n",
       "      <td>Some key issues related to data governance in ...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>How can blockchains potentially eliminate the ...</td>\n",
       "      <td>[22 \\n \\nmore, such delayed mechanism could be...</td>\n",
       "      <td>Blockchains can potentially eliminate the need...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>What are some proposed solutions to improve sc...</td>\n",
       "      <td>[22 \\n \\nmore, such delayed mechanism could be...</td>\n",
       "      <td>Some proposed solutions to improve scalability...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>What are some solutions that enable legacy sys...</td>\n",
       "      <td>[23 \\n \\ndevelopment, and share blockchain sol...</td>\n",
       "      <td>Some solutions that enable legacy systems to c...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Name three well-known players in the Blockchai...</td>\n",
       "      <td>[23 \\n \\ndevelopment, and share blockchain sol...</td>\n",
       "      <td>Three well-known players in the Blockchain as ...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>What are some alternatives to blockchain techn...</td>\n",
       "      <td>[24 \\n \\nagement of smart contracts , and also...</td>\n",
       "      <td>Some alternatives to blockchain technology tha...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>How does Amazon's Quantum Ledger Database comb...</td>\n",
       "      <td>[24 \\n \\nagement of smart contracts , and also...</td>\n",
       "      <td>Amazon's Quantum Ledger Database combines the ...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>What are some advantages of decentralized stor...</td>\n",
       "      <td>[25 \\n \\ntions that run when disconnected from...</td>\n",
       "      <td>Decentralized storage systems like IPFS and St...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>According to the document, what are some poten...</td>\n",
       "      <td>[25 \\n \\ntions that run when disconnected from...</td>\n",
       "      <td>According to the document, some potential impr...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>What are the advantages and disadvantages of d...</td>\n",
       "      <td>[26 \\n \\n2. Bitcoin developer, https://develop...</td>\n",
       "      <td>The advantages and disadvantages of different ...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Compare and contrast the Solana blockchain arc...</td>\n",
       "      <td>[26 \\n \\n2. Bitcoin developer, https://develop...</td>\n",
       "      <td>To compare and contrast the Solana blockchain ...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>What is the difference between Ethereum and EO...</td>\n",
       "      <td>[Information Processing &amp; Management  58(3), \\...</td>\n",
       "      <td>According to the source \"Ethereum VS EOS,\" the...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>According to the source \"A review on consensus...</td>\n",
       "      <td>[Information Processing &amp; Management  58(3), \\...</td>\n",
       "      <td>According to the source \"A review on consensus...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>What are some examples of permissioned blockch...</td>\n",
       "      <td>[27 \\n \\n24. Qassim Nasir, Ilham A. Qasse, Man...</td>\n",
       "      <td>Some examples of permissioned blockchain solut...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>How does the Solana blockchain platform compar...</td>\n",
       "      <td>[27 \\n \\n24. Qassim Nasir, Ilham A. Qasse, Man...</td>\n",
       "      <td>The comparison between the Solana blockchain p...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>What are some popular blockchain platforms men...</td>\n",
       "      <td>[In International Conference for Emerging Tech...</td>\n",
       "      <td>Some popular blockchain platforms mentioned in...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>What are some examples of peer-to-peer cloud s...</td>\n",
       "      <td>[In International Conference for Emerging Tech...</td>\n",
       "      <td>Some examples of peer-to-peer cloud storage ne...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0   What are the key issues preventing the wide ad...   \n",
       "1   How does blockchain technology provide data se...   \n",
       "2   What is the projected growth rate of the block...   \n",
       "3   What are some of the challenges facing enterpr...   \n",
       "4   What are the key issues that need to be addres...   \n",
       "5   How can blockchains enhance security and integ...   \n",
       "6   How does Solana's blockchain technology addres...   \n",
       "7   Explain the main data structure of a blockchai...   \n",
       "8   Explain the structure of the main body of each...   \n",
       "9   Discuss the role and significance of smart con...   \n",
       "10  What are the two core proof-based algorithms m...   \n",
       "11  What are the performance and scalability issue...   \n",
       "12  What are the advantages and disadvantages of p...   \n",
       "13  Can you provide examples of different types of...   \n",
       "14  What are the main differences between public a...   \n",
       "15  Why did the author choose six specific blockch...   \n",
       "16  What are the main differences between public b...   \n",
       "17  How does Solana differentiate itself from othe...   \n",
       "18  How does Bitcoin's concept of \"wallet address\"...   \n",
       "19  What is the potential drawback of Bitcoin's tr...   \n",
       "20  Explain the concept of smart contracts in Ethe...   \n",
       "21  In the context of Bitcoin, what are the potent...   \n",
       "22  What are the three types of transactions in Et...   \n",
       "23  How does Gas play a role in Ethereum transacti...   \n",
       "24  What are the three main features of EOS mentio...   \n",
       "25  Why was the number 21 chosen for the selected ...   \n",
       "26  What is the purpose of the rotation mechanism ...   \n",
       "27  How does Hyperledger Fabric differ from tradit...   \n",
       "28  What are the three main components in Hyperled...   \n",
       "29  How does the \"execute-order-validate\" mechanis...   \n",
       "30  How does Hyperledger Fabric ensure confidentia...   \n",
       "31  What are the two types of membership in Corda ...   \n",
       "32  What are the three types of notary service mod...   \n",
       "33  How does the DAG (Directed Acyclic Graph) syst...   \n",
       "34  Explain the concept of Proof of History in the...   \n",
       "35  How does the DAG (Directed Acyclic Graph) data...   \n",
       "36  How does Solana handle the synchronization of ...   \n",
       "37  Why is it important for organizations to caref...   \n",
       "38  What are the critical issues that enterprises ...   \n",
       "39  How do performance and scalability factors lim...   \n",
       "40  How can innovative data structures and algorit...   \n",
       "41  What are some key issues related to data gover...   \n",
       "42  How can blockchains potentially eliminate the ...   \n",
       "43  What are some proposed solutions to improve sc...   \n",
       "44  What are some solutions that enable legacy sys...   \n",
       "45  Name three well-known players in the Blockchai...   \n",
       "46  What are some alternatives to blockchain techn...   \n",
       "47  How does Amazon's Quantum Ledger Database comb...   \n",
       "48  What are some advantages of decentralized stor...   \n",
       "49  According to the document, what are some poten...   \n",
       "50  What are the advantages and disadvantages of d...   \n",
       "51  Compare and contrast the Solana blockchain arc...   \n",
       "52  What is the difference between Ethereum and EO...   \n",
       "53  According to the source \"A review on consensus...   \n",
       "54  What are some examples of permissioned blockch...   \n",
       "55  How does the Solana blockchain platform compar...   \n",
       "56  What are some popular blockchain platforms men...   \n",
       "57  What are some examples of peer-to-peer cloud s...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [From Bitcoin to Solana – Innovating Blockchai...   \n",
       "1   [From Bitcoin to Solana – Innovating Blockchai...   \n",
       "2   [2 \\n \\nchain market size is expected to grow ...   \n",
       "3   [2 \\n \\nchain market size is expected to grow ...   \n",
       "4   [3 \\n \\nScalability.  Scalability  is the seco...   \n",
       "5   [3 \\n \\nScalability.  Scalability  is the seco...   \n",
       "6   [4 \\n \\ntionary nature of blockchain technolog...   \n",
       "7   [4 \\n \\ntionary nature of blockchain technolog...   \n",
       "8   [5 \\n \\nTX Counter\\nTX TX TXprevious block \\nh...   \n",
       "9   [5 \\n \\nTX Counter\\nTX TX TXprevious block \\nh...   \n",
       "10  [6 \\n \\nConsensus issues . The c onsensus algo...   \n",
       "11  [6 \\n \\nConsensus issues . The c onsensus algo...   \n",
       "12  [7 \\n \\nMany other issues also impact the matu...   \n",
       "13  [7 \\n \\nMany other issues also impact the matu...   \n",
       "14  [8 \\n \\n  Ethereum  Hyperledger ： \\nGeneral op...   \n",
       "15  [8 \\n \\n  Ethereum  Hyperledger ： \\nGeneral op...   \n",
       "16  [9 \\n \\nblockchain structures and algorithms c...   \n",
       "17  [9 \\n \\nblockchain structures and algorithms c...   \n",
       "18  [10 \\n \\n3 Analysis of the Selected Main Frame...   \n",
       "19  [10 \\n \\n3 Analysis of the Selected Main Frame...   \n",
       "20  [11 \\n \\nThis case above  is only a one -trans...   \n",
       "21  [11 \\n \\nThis case above  is only a one -trans...   \n",
       "22  [12 \\n \\nof users, can be digitalized. This om...   \n",
       "23  [12 \\n \\nof users, can be digitalized. This om...   \n",
       "24  [13 \\n \\n EOS provides not only tools for DApp...   \n",
       "25  [13 \\n \\n EOS provides not only tools for DApp...   \n",
       "26  [14 \\n \\n21 selected block producers\\nConsensu...   \n",
       "27  [14 \\n \\n21 selected block producers\\nConsensu...   \n",
       "28  [15 \\n \\nFig. 9. Hyperledger Fabric Architectu...   \n",
       "29  [15 \\n \\nFig. 9. Hyperledger Fabric Architectu...   \n",
       "30  [16 \\n \\nAnother  attractive attribute of Fabr...   \n",
       "31  [16 \\n \\nAnother  attractive attribute of Fabr...   \n",
       "32  [17 \\n \\nWorking node\\nNotary serviceNotary Da...   \n",
       "33  [17 \\n \\nWorking node\\nNotary serviceNotary Da...   \n",
       "34  [18 \\n \\nbecause DAG system needn’t to synchro...   \n",
       "35  [18 \\n \\nbecause DAG system needn’t to synchro...   \n",
       "36  [19 \\n \\nFig. 14. Components of Solana  \\nThen...   \n",
       "37  [19 \\n \\nFig. 14. Components of Solana  \\nThen...   \n",
       "38  [20 \\n \\nBusiness Model drives the solution. B...   \n",
       "39  [20 \\n \\nBusiness Model drives the solution. B...   \n",
       "40  [21 \\n \\nthe original Bitcoin and Ethereaum by...   \n",
       "41  [21 \\n \\nthe original Bitcoin and Ethereaum by...   \n",
       "42  [22 \\n \\nmore, such delayed mechanism could be...   \n",
       "43  [22 \\n \\nmore, such delayed mechanism could be...   \n",
       "44  [23 \\n \\ndevelopment, and share blockchain sol...   \n",
       "45  [23 \\n \\ndevelopment, and share blockchain sol...   \n",
       "46  [24 \\n \\nagement of smart contracts , and also...   \n",
       "47  [24 \\n \\nagement of smart contracts , and also...   \n",
       "48  [25 \\n \\ntions that run when disconnected from...   \n",
       "49  [25 \\n \\ntions that run when disconnected from...   \n",
       "50  [26 \\n \\n2. Bitcoin developer, https://develop...   \n",
       "51  [26 \\n \\n2. Bitcoin developer, https://develop...   \n",
       "52  [Information Processing & Management  58(3), \\...   \n",
       "53  [Information Processing & Management  58(3), \\...   \n",
       "54  [27 \\n \\n24. Qassim Nasir, Ilham A. Qasse, Man...   \n",
       "55  [27 \\n \\n24. Qassim Nasir, Ilham A. Qasse, Man...   \n",
       "56  [In International Conference for Emerging Tech...   \n",
       "57  [In International Conference for Emerging Tech...   \n",
       "\n",
       "                                     reference_answer reference_answer_by  \\\n",
       "0   The key issues preventing the wide adoption of...  ai (gpt-3.5-turbo)   \n",
       "1   Blockchain technology provides data security a...  ai (gpt-3.5-turbo)   \n",
       "2   The projected growth rate of the blockchain ma...  ai (gpt-3.5-turbo)   \n",
       "3   Some of the challenges facing enterprise adopt...  ai (gpt-3.5-turbo)   \n",
       "4   The key issues that need to be addressed in or...  ai (gpt-3.5-turbo)   \n",
       "5   Blockchains can enhance security and integrity...  ai (gpt-3.5-turbo)   \n",
       "6   Solana's blockchain technology addresses criti...  ai (gpt-3.5-turbo)   \n",
       "7   The main data structure of a blockchain is a c...  ai (gpt-3.5-turbo)   \n",
       "8   The main body of each block in the blockchain ...  ai (gpt-3.5-turbo)   \n",
       "9   Smart contracts play a crucial role in a block...  ai (gpt-3.5-turbo)   \n",
       "10  The two core proof-based algorithms mentioned ...  ai (gpt-3.5-turbo)   \n",
       "11  The performance issues faced by typical blockc...  ai (gpt-3.5-turbo)   \n",
       "12  The advantages of permissionless blockchains a...  ai (gpt-3.5-turbo)   \n",
       "13  Examples of different types of blockchain plat...  ai (gpt-3.5-turbo)   \n",
       "14  The main differences between public and privat...  ai (gpt-3.5-turbo)   \n",
       "15  The author chose six specific blockchain platf...  ai (gpt-3.5-turbo)   \n",
       "16  The main differences between public blockchain...  ai (gpt-3.5-turbo)   \n",
       "17  Solana differentiates itself from other blockc...  ai (gpt-3.5-turbo)   \n",
       "18  Bitcoin's concept of \"wallet address\" differs ...  ai (gpt-3.5-turbo)   \n",
       "19  The potential drawback of Bitcoin's transactio...  ai (gpt-3.5-turbo)   \n",
       "20  In Ethereum, smart contracts are a key concept...  ai (gpt-3.5-turbo)   \n",
       "21  In the context of Bitcoin, there are up to 5 p...  ai (gpt-3.5-turbo)   \n",
       "22  The three types of transactions in Ethereum ar...  ai (gpt-3.5-turbo)   \n",
       "23  Gas plays a role in Ethereum transactions by r...  ai (gpt-3.5-turbo)   \n",
       "24  The three main features of EOS mentioned in th...  ai (gpt-3.5-turbo)   \n",
       "25  The number 21 was chosen for the selected bloc...  ai (gpt-3.5-turbo)   \n",
       "26  The purpose of the rotation mechanism in the s...  ai (gpt-3.5-turbo)   \n",
       "27  Hyperledger Fabric differs from traditional bl...  ai (gpt-3.5-turbo)   \n",
       "28  The three main components in Hyperledger Fabri...  ai (gpt-3.5-turbo)   \n",
       "29  The \"execute-order-validate\" mechanism in Hype...  ai (gpt-3.5-turbo)   \n",
       "30  Hyperledger Fabric ensures confidentiality in ...  ai (gpt-3.5-turbo)   \n",
       "31  The two types of membership in Corda are worki...  ai (gpt-3.5-turbo)   \n",
       "32  The three types of notary service models in Co...  ai (gpt-3.5-turbo)   \n",
       "33  The DAG system improves the TPS of a blockchai...  ai (gpt-3.5-turbo)   \n",
       "34  Proof of History is a mechanism used in the So...  ai (gpt-3.5-turbo)   \n",
       "35  The DAG (Directed Acyclic Graph) data structur...  ai (gpt-3.5-turbo)   \n",
       "36  Solana handles the synchronization of transact...  ai (gpt-3.5-turbo)   \n",
       "37  It is important for organizations to carefully...  ai (gpt-3.5-turbo)   \n",
       "38  The critical issues that enterprises should co...  ai (gpt-3.5-turbo)   \n",
       "39  Performance and scalability factors limit the ...  ai (gpt-3.5-turbo)   \n",
       "40  Innovative data structures and algorithms can ...  ai (gpt-3.5-turbo)   \n",
       "41  Some key issues related to data governance in ...  ai (gpt-3.5-turbo)   \n",
       "42  Blockchains can potentially eliminate the need...  ai (gpt-3.5-turbo)   \n",
       "43  Some proposed solutions to improve scalability...  ai (gpt-3.5-turbo)   \n",
       "44  Some solutions that enable legacy systems to c...  ai (gpt-3.5-turbo)   \n",
       "45  Three well-known players in the Blockchain as ...  ai (gpt-3.5-turbo)   \n",
       "46  Some alternatives to blockchain technology tha...  ai (gpt-3.5-turbo)   \n",
       "47  Amazon's Quantum Ledger Database combines the ...  ai (gpt-3.5-turbo)   \n",
       "48  Decentralized storage systems like IPFS and St...  ai (gpt-3.5-turbo)   \n",
       "49  According to the document, some potential impr...  ai (gpt-3.5-turbo)   \n",
       "50  The advantages and disadvantages of different ...  ai (gpt-3.5-turbo)   \n",
       "51  To compare and contrast the Solana blockchain ...  ai (gpt-3.5-turbo)   \n",
       "52  According to the source \"Ethereum VS EOS,\" the...  ai (gpt-3.5-turbo)   \n",
       "53  According to the source \"A review on consensus...  ai (gpt-3.5-turbo)   \n",
       "54  Some examples of permissioned blockchain solut...  ai (gpt-3.5-turbo)   \n",
       "55  The comparison between the Solana blockchain p...  ai (gpt-3.5-turbo)   \n",
       "56  Some popular blockchain platforms mentioned in...  ai (gpt-3.5-turbo)   \n",
       "57  Some examples of peer-to-peer cloud storage ne...  ai (gpt-3.5-turbo)   \n",
       "\n",
       "              query_by  \n",
       "0   ai (gpt-3.5-turbo)  \n",
       "1   ai (gpt-3.5-turbo)  \n",
       "2   ai (gpt-3.5-turbo)  \n",
       "3   ai (gpt-3.5-turbo)  \n",
       "4   ai (gpt-3.5-turbo)  \n",
       "5   ai (gpt-3.5-turbo)  \n",
       "6   ai (gpt-3.5-turbo)  \n",
       "7   ai (gpt-3.5-turbo)  \n",
       "8   ai (gpt-3.5-turbo)  \n",
       "9   ai (gpt-3.5-turbo)  \n",
       "10  ai (gpt-3.5-turbo)  \n",
       "11  ai (gpt-3.5-turbo)  \n",
       "12  ai (gpt-3.5-turbo)  \n",
       "13  ai (gpt-3.5-turbo)  \n",
       "14  ai (gpt-3.5-turbo)  \n",
       "15  ai (gpt-3.5-turbo)  \n",
       "16  ai (gpt-3.5-turbo)  \n",
       "17  ai (gpt-3.5-turbo)  \n",
       "18  ai (gpt-3.5-turbo)  \n",
       "19  ai (gpt-3.5-turbo)  \n",
       "20  ai (gpt-3.5-turbo)  \n",
       "21  ai (gpt-3.5-turbo)  \n",
       "22  ai (gpt-3.5-turbo)  \n",
       "23  ai (gpt-3.5-turbo)  \n",
       "24  ai (gpt-3.5-turbo)  \n",
       "25  ai (gpt-3.5-turbo)  \n",
       "26  ai (gpt-3.5-turbo)  \n",
       "27  ai (gpt-3.5-turbo)  \n",
       "28  ai (gpt-3.5-turbo)  \n",
       "29  ai (gpt-3.5-turbo)  \n",
       "30  ai (gpt-3.5-turbo)  \n",
       "31  ai (gpt-3.5-turbo)  \n",
       "32  ai (gpt-3.5-turbo)  \n",
       "33  ai (gpt-3.5-turbo)  \n",
       "34  ai (gpt-3.5-turbo)  \n",
       "35  ai (gpt-3.5-turbo)  \n",
       "36  ai (gpt-3.5-turbo)  \n",
       "37  ai (gpt-3.5-turbo)  \n",
       "38  ai (gpt-3.5-turbo)  \n",
       "39  ai (gpt-3.5-turbo)  \n",
       "40  ai (gpt-3.5-turbo)  \n",
       "41  ai (gpt-3.5-turbo)  \n",
       "42  ai (gpt-3.5-turbo)  \n",
       "43  ai (gpt-3.5-turbo)  \n",
       "44  ai (gpt-3.5-turbo)  \n",
       "45  ai (gpt-3.5-turbo)  \n",
       "46  ai (gpt-3.5-turbo)  \n",
       "47  ai (gpt-3.5-turbo)  \n",
       "48  ai (gpt-3.5-turbo)  \n",
       "49  ai (gpt-3.5-turbo)  \n",
       "50  ai (gpt-3.5-turbo)  \n",
       "51  ai (gpt-3.5-turbo)  \n",
       "52  ai (gpt-3.5-turbo)  \n",
       "53  ai (gpt-3.5-turbo)  \n",
       "54  ai (gpt-3.5-turbo)  \n",
       "55  ai (gpt-3.5-turbo)  \n",
       "56  ai (gpt-3.5-turbo)  \n",
       "57  ai (gpt-3.5-turbo)  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533589255,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "1CHzjKlKSvkI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelledRagDataExample(query='What are the key issues preventing the wide adoption of blockchain technology in enterprise applications, and how has Solana addressed these issues?', query_by=CreatedBy(model_name='gpt-3.5-turbo', type=<CreatedByType.AI: 'ai'>), reference_contexts=['From Bitcoin to Solana – Innovating Blockchain towards \\nEnterprise Applications  \\nXiangyu Li, Xinyu Wang , Tingli Kong , Junhao Zheng and Min Luo  \\nGeorgia Institute of Technology, Atlanta, GA 30332, USA  \\nmluo60@gatech.edu  \\nAbstract. This survey presents a comprehe nsive study of recent advances in \\nblockchain technologies ， focusing on how issues that affecting the enterprise \\nadoption were progressively addressed from the original Bitcoin system to \\nEthereum, to Solana etc. Key issues preventing the wide adoption ar e scalability \\nand performance, while r ecent advances in Solana has clearly demonstrated that \\nit is possible to significantly improve on those issues by innovating on data \\nstructure, processes and algorithms by consolidating various time -consuming \\nalgorithms a nd security enforcements, and differentiate and balance users and \\ntheir responsibilities and rights, while maintaining the required security and in-\\ntegrity that blockchain systems inherently offer.  \\nKeywords:  Blockchain, Distributed Ledger , Consensus , Proof  of Work, Proof \\nof History Scalability, Performance, Security,  \\n1 Introduction  \\n1.1 Rise of Blockchain Technology  \\nThe blockchain is a purely distributed peer -to-peer system of ledgers that utilizes \\nsome well -articulated  software constructs  of algorithm s, collabora tively peers to rec-\\nord and negotiate  the informational content of ordered and connected blocks of trans-\\naction data together with cryptographic and security  enrichments to achieve integrity. \\nIt was first introduced by Bitcoin in 2009 and has been becoming a  mainstream tech-\\nnology. It has be en used in various industries, such as  financial, healthcare, supply \\nchain, logistics, and many other s. Such distributed ledger s are  designed to provide a \\npermanent, tamper -proof r ecord of business transactions, as they can  be utilized to \\nimprove collaboration, enable provenance, speed up transaction settlements or enable \\ntransparency.  \\nBlockchain can also be viewed as  a decentralized database running  on a peer -to-\\npeer network, where  each node/computer (or some selected group ) maintains  a copy \\nof the current ledger. It offers d ata security and reliability as the data canno t be easily \\nmodified  while  the redundant copies make data loss unlikely.  \\nBlockchain innovated in  how digital information is stored, verified and exchanged, \\nand was inherently designed and developed to create secure, reliable and transparent \\nbusiness processes for enterprises. One of the surveys reveals that the global block-'], reference_answer='The key issues preventing the wide adoption of blockchain technology in enterprise applications are scalability and performance. However, recent advances in Solana have demonstrated that it is possible to significantly improve on these issues. Solana has achieved this by innovating on data structure, processes, and algorithms. It has consolidated various time-consuming algorithms and security enforcements, and has differentiated and balanced users and their responsibilities and rights while maintaining the required security and integrity that blockchain systems inherently offer.', reference_answer_by=CreatedBy(model_name='gpt-3.5-turbo', type=<CreatedByType.AI: 'ai'>))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_dataset.examples[0] #query, reference_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533589255,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "1vycmNuESpm_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# build basic RAG system\n",
    "index = VectorStoreIndex.from_documents(documents=documents)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_evaluator_pack = RagEvaluatorPack(rag_dataset=rag_dataset, query_engine=query_engine, judge_llm=gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533589255,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "VH_9noT1Srsr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:   5%|▌         | 1/20 [00:02<00:49,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  10%|█         | 2/20 [00:02<00:21,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  25%|██▌       | 5/20 [00:02<00:05,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  40%|████      | 8/20 [00:03<00:02,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  50%|█████     | 10/20 [00:03<00:01,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  60%|██████    | 12/20 [00:03<00:01,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  70%|███████   | 14/20 [00:03<00:00,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  80%|████████  | 16/20 [00:03<00:00,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  90%|█████████ | 18/20 [00:03<00:00,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions: 100%|██████████| 20/20 [00:04<00:00,  4.36it/s]\n",
      "Batch processing of predictions:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:   5%|▌         | 1/20 [00:02<00:43,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  10%|█         | 2/20 [00:02<00:20,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  35%|███▌      | 7/20 [00:02<00:03,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  45%|████▌     | 9/20 [00:02<00:02,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  55%|█████▌    | 11/20 [00:03<00:01,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  70%|███████   | 14/20 [00:03<00:00,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  85%|████████▌ | 17/20 [00:03<00:00, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions: 100%|██████████| 20/20 [00:04<00:00,  4.49it/s]\n",
      "Batch processing of predictions:   0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:   6%|▌         | 1/18 [00:02<00:40,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  11%|█         | 2/18 [00:02<00:16,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  28%|██▊       | 5/18 [00:02<00:04,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  50%|█████     | 9/18 [00:02<00:01,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  61%|██████    | 11/18 [00:03<00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  72%|███████▏  | 13/18 [00:03<00:00,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions:  89%|████████▉ | 16/18 [00:03<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of predictions: 100%|██████████| 18/18 [00:04<00:00,  3.97it/s]\n",
      "Batch processing of evaluations:   0%|          | 0/12.8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of evaluations:   8%|▊         | 1/12.8 [00:04<00:48,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of evaluations:  23%|██▎       | 3/12.8 [00:08<00:27,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of evaluations:  39%|███▉      | 5/12.8 [00:13<00:20,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of evaluations:  47%|████▋     | 6/12.8 [00:17<00:20,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of evaluations:  62%|██████▎   | 8/12.8 [00:21<00:12,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of evaluations:  70%|███████   | 9/12.8 [00:26<00:11,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of evaluations:  78%|███████▊  | 10/12.8 [00:30<00:09,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of evaluations:  94%|█████████▍| 12/12.8 [00:35<00:02,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of evaluations: 102%|██████████| 13/12.8 [00:41<00:00,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of evaluations: 14it [00:45,  3.84s/it]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of evaluations: 15it [00:50,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch processing of evaluations:  94%|█████████▍| 12/12.8 [00:54<00:03,  4.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# evaluate using the RagEvaluatorPack\n",
    "benchmark_df = await rag_evaluator_pack.arun(\n",
    "    batch_size=20,  # batches the number of openai api calls to make\n",
    "    sleep_time_in_seconds=1,  # seconds to sleep before making an api call\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533589255,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "LsYYEXI-St__"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rag</th>\n",
       "      <th>base_rag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_correctness_score</th>\n",
       "      <td>4.181034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_relevancy_score</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_faithfulness_score</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_context_similarity_score</th>\n",
       "      <td>0.942123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rag                            base_rag\n",
       "metrics                                \n",
       "mean_correctness_score         4.181034\n",
       "mean_relevancy_score           1.000000\n",
       "mean_faithfulness_score        1.000000\n",
       "mean_context_similarity_score  0.942123"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aX7xg4hAohDl"
   },
   "source": [
    "# Retrieval Evaluation\n",
    "\n",
    "Evaluates the quality of any Retriever module defined in LlamaIndex.\n",
    "\n",
    "To assess the quality of a Retriever module in LlamaIndex, we use metrics like hit-rate and MRR. These compare retrieved results to ground-truth context for any question. For simpler evaluation dataset creation, we utilize synthetic data generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXKPpQ0tP76P"
   },
   "source": [
    "Hit Rate:\n",
    "MRR:\n",
    "\n",
    "Document -> D\n",
    "\n",
    "D -> N1, N2, N3, N4, N5 -> Index/ Retriever\n",
    "\n",
    "(Q1, N1)\n",
    "(Q2, N1)\n",
    "(Q3, N2)\n",
    "(Q4, N2)\n",
    "(Q5, N3)\n",
    "(Q6, N3)\n",
    "(Q7, N4)\n",
    "(Q8, N4)\n",
    "(Q9, N5)\n",
    "(Q10, N5)\n",
    "\n",
    "Q1 -> Index/ Retriever -> N2, N1, N3 -> 1 -> 1/2\n",
    "\n",
    "Q2 -> Index/ Retriever -> N5, N4, N3 -> 0 -> 0\n",
    "\n",
    "Q3 -> Index/ Retriever -> N1, N2, N3 -> 1 -> 1/2\n",
    "\n",
    "Q4 -> Index/ Retriever -> N2, N3, N5 -> 1 -> 1/1\n",
    "\n",
    "Q5 -> Index/ Retriever -> N3, N1, N4 -> 1 -> 1/1\n",
    "\n",
    "Q6 -> Index/ Retriever -> N1, N2, N3 -> 1 -> 1/3\n",
    "\n",
    "Q7 -> Index/ Retriever -> N4, N1, N2 -> 1 -> 1/1\n",
    "\n",
    "Q8 -> Index/ Retriever -> N1, N3, N4 -> 1 -> 1/3\n",
    "\n",
    "Q9 -> Index/ Retriever -> N2, N3, N4 -> 0 -> 0\n",
    "\n",
    "Q10 -> Index/ Retriever -> N2, N5, N3 -> 1 -> 1/2\n",
    "\n",
    "Hit Rate: 8/10 -> 80%\n",
    "\n",
    "MRR: (0.5 + 0 + 0.5 + 1 + 1 + 0.33 + 1 + 0.33 + 0 + 0.5)/10 -> 55%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.text_splitter import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533589256,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "wFtWgxqj1x7D"
   },
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(\"./data/paul_graham/\")\n",
    "documents = reader.load_data()\n",
    "\n",
    "# create parser and parse document into nodes\n",
    "parser = SentenceSplitter(chunk_size=1024, chunk_overlap=100)\n",
    "nodes = parser(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "aborted",
     "timestamp": 1703533589256,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "L8WLcpA-12LB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "vector_index = VectorStoreIndex(nodes, embed_model=OpenAIEmbedding(model='text-embedding-3-small'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "aborted",
     "timestamp": 1703533589257,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "XZllZ2u5oj0X",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the retriever\n",
    "retriever = vector_index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1703533589258,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "A5R3H3erqx_i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "retrieved_nodes = retriever.retrieve(eval_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.6-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.2-cp312-cp312-win_amd64.whl.metadata (111 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.6-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.0/8.1 MB 5.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.4/8.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.7/8.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.0/8.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.3/8.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.3/8.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 5.8 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.3-cp312-cp312-win_amd64.whl (226 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.2-cp312-cp312-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.0/2.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.3 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 4.9 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp312-cp312-win_amd64.whl (73 kB)\n",
      "Installing collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.2 kiwisolver-1.4.9 matplotlib-3.10.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1703533589258,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "VMHGPbUiqned"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** f380d7c1-c403-416f-9eb4-86838cc7cf17<br>**Similarity:** 0.6167315224318201<br>**Text:** What I Worked On\n",
       "\n",
       "February 2021\n",
       "\n",
       "Before college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n",
       "\n",
       "The first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district's 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain's lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\n",
       "\n",
       "The language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\n",
       "\n",
       "I was puzzled by the 1401. I couldn't figure out what to do with it. And in retrospect there's not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn't have any data stored on punched cards. The only other option was to do things that didn't rely on any input, like calculate approximations of pi, but I didn't know enough math to do anything interesting of that type. So I'm not surprised I can't remember any programs I wrote, because they can't have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn't. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager's expression made clear.\n",
       "\n",
       "With microcomputers, everything changed. Now you could h...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 76d8546d-4e69-4ae9-bf71-fb9670f4ad01<br>**Similarity:** 0.5289862943025382<br>**Text:** All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\n",
       "\n",
       "AI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven't tried rereading The Moon is a Harsh Mistress, so I don't know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we'd have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most. All you had to do was teach SHRDLU more words.\n",
       "\n",
       "There weren't any classes in AI at Cornell then, not even graduate classes, so I started trying to teach myself. Which meant learning Lisp, since in those days Lisp was regarded as the language of AI. The commonly used programming languages then were pretty primitive, and programmers' ideas correspondingly so. The default language at Cornell was a Pascal-like language called PL/I, and the situation was similar elsewhere. Learning Lisp expanded my concept of a program so fast that it was years before I started to have a sense of where the new limits were. This was more like it; this was what I had expected college to do. It wasn't happening in a class, like it was supposed to, but that was ok. For the next couple years I was on a roll. I knew what I was going to do.\n",
       "\n",
       "For my undergraduate thesis, I reverse-engineered SHRDLU. My God did I love working on that program. It was a pleasing bit of code, but what made it even more exciting was my belief — hard to imagine now, but not unique in 1985 — that it was already climbing the lower slopes of intelligence.\n",
       "\n",
       "I had gotten into a program at Cornell that didn't make you choose a major. You could take whatever classes you liked, and choose whatever you liked to put on your degree. I of c...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for node in retrieved_nodes:\n",
    "    display_source_node(node, source_length=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1703533589258,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "R2EzD6m_rDU4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "qa_dataset = generate_question_context_pairs(nodes[0:2], llm=gpt4, num_questions_per_chunk=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'200a97cc-f66d-44be-8f38-eb056c19883a': \"Describe the evolution of the author's programming experiences from using the IBM 1401 to acquiring a TRS-80. How did these experiences influence their interest in programming?\",\n",
       " 'a792c6d8-b9ef-42c6-b8cf-fa7fba241f4e': \"Discuss the author's initial perception of studying philosophy in college and how their views changed over time. What factors contributed to their decision to switch to studying AI?\",\n",
       " 'a91d6688-bd0b-415c-bd07-7dc6a31d42bf': \"Describe the factors that influenced the author's decision to switch from studying philosophy to pursuing artificial intelligence in the mid-1980s. How did specific works and experiences contribute to this decision?\",\n",
       " 'a8413bde-f5e1-4c4b-a591-5ed15f7490db': \"Analyze the author's perspective on the state of artificial intelligence during their first year of graduate school. What realization did they come to about AI as it was practiced at the time, and how did this impact their academic and career focus?\"}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama_index.llms.groq\n",
      "  Downloading llama_index_llms_groq-0.4.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama_index.llms.groq) (0.13.3)\n",
      "Collecting llama-index-llms-openai-like<0.6,>=0.5.0 (from llama_index.llms.groq)\n",
      "  Downloading llama_index_llms_openai_like-0.5.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (3.12.15)\n",
      "Requirement already satisfied: aiosqlite in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (2025.7.0)\n",
      "Requirement already satisfied: httpx in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (1.3.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (3.5)\n",
      "Requirement already satisfied: nltk>3.8.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (3.9.1)\n",
      "Requirement already satisfied: numpy in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (2.3.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (11.3.0)\n",
      "Requirement already satisfied: platformdirs in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (4.4.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (2.0.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (0.11.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (4.14.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (0.9.0)\n",
      "Requirement already satisfied: wrapt in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (1.17.3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.6,>=0.5.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-llms-openai-like<0.6,>=0.5.0->llama_index.llms.groq) (0.5.4)\n",
      "Requirement already satisfied: transformers<5,>=4.37.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-llms-openai-like<0.6,>=0.5.0->llama_index.llms.groq) (4.56.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (1.20.1)\n",
      "Requirement already satisfied: griffe in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (1.13.0)\n",
      "Requirement already satisfied: jinja2 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (3.1.6)\n",
      "Requirement already satisfied: openai<2,>=1.81.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-llms-openai<0.6,>=0.5.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama_index.llms.groq) (1.102.0)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (0.4.0)\n",
      "Requirement already satisfied: click in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (8.2.1)\n",
      "Requirement already satisfied: joblib in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (2025.7.34)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (3.2.4)\n",
      "Requirement already satisfied: colorama in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from tqdm<5,>=4.66.1->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (0.4.6)\n",
      "Requirement already satisfied: filelock in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama_index.llms.groq) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama_index.llms.groq) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama_index.llms.groq) (24.2)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama_index.llms.groq) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama_index.llms.groq) (0.6.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (3.26.1)\n",
      "Requirement already satisfied: anyio in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.6,>=0.5.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama_index.llms.groq) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.6,>=0.5.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama_index.llms.groq) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.6,>=0.5.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama_index.llms.groq) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama_index.llms.groq) (3.0.2)\n",
      "Downloading llama_index_llms_groq-0.4.0-py3-none-any.whl (3.7 kB)\n",
      "Downloading llama_index_llms_openai_like-0.5.0-py3-none-any.whl (4.6 kB)\n",
      "Installing collected packages: llama-index-llms-openai-like, llama_index.llms.groq\n",
      "Successfully installed llama-index-llms-openai-like-0.5.0 llama_index.llms.groq-0.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_index.llms.groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = Groq(model='llama-3.2-90b-vision-preview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_QA_GENERATE_PROMPT_TMPL = \"\"\"\\\n",
    "Context information is below.\n",
    "\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "\n",
    "Given the context information and not prior knowledge.\n",
    "generate only questions based on the below query.\n",
    "\n",
    "You are a Teacher/ Professor. Your task is to setup \\\n",
    "{num_questions_per_chunk} questions for an upcoming \\\n",
    "quiz/examination. The questions should be diverse in nature \\\n",
    "across the document. Restrict the questions to the \\\n",
    "context information provided.\"\n",
    "\n",
    "Just provide the questions and nothing else\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1703533589258,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "R2EzD6m_rDU4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m qa_dataset_groq = \u001b[43mgenerate_question_context_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_questions_per_chunk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                                                  \u001b[49m\u001b[43mqa_generate_prompt_tmpl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEFAULT_QA_GENERATE_PROMPT_TMPL\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\llama_index\\core\\llama_dataset\\legacy\\embedding.py:91\u001b[39m, in \u001b[36mgenerate_qa_embedding_pairs\u001b[39m\u001b[34m(nodes, llm, qa_generate_prompt_tmpl, num_questions_per_chunk)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node_id, text \u001b[38;5;129;01min\u001b[39;00m tqdm(node_dict.items()):\n\u001b[32m     88\u001b[39m     query = qa_generate_prompt_tmpl.format(\n\u001b[32m     89\u001b[39m         context_str=text, num_questions_per_chunk=num_questions_per_chunk\n\u001b[32m     90\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     result = \u001b[38;5;28mstr\u001b[39m(response).strip().split(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     94\u001b[39m     questions = [\n\u001b[32m     95\u001b[39m         re.sub(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m^\u001b[39m\u001b[33m\\\u001b[39m\u001b[33md+[\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m).\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms]\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, question).strip() \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m result\n\u001b[32m     96\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:317\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    320\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\llama_index\\llms\\openai_like\\base.py:145\u001b[39m, in \u001b[36mOpenAILike.complete\u001b[39m\u001b[34m(self, prompt, formatted, **kwargs)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m formatted:\n\u001b[32m    143\u001b[39m     prompt = \u001b[38;5;28mself\u001b[39m.completion_to_prompt(prompt)\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:317\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    320\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:435\u001b[39m, in \u001b[36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[39m\u001b[34m(_self, *args, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m event_id = callback_manager.on_event_start(\n\u001b[32m    427\u001b[39m     CBEventType.LLM,\n\u001b[32m    428\u001b[39m     payload={\n\u001b[32m   (...)\u001b[39m\u001b[32m    432\u001b[39m     },\n\u001b[32m    433\u001b[39m )\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     f_return_val = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    437\u001b[39m     callback_manager.on_event_end(\n\u001b[32m    438\u001b[39m         CBEventType.LLM,\n\u001b[32m    439\u001b[39m         payload={EventPayload.EXCEPTION: e},\n\u001b[32m    440\u001b[39m         event_id=event_id,\n\u001b[32m    441\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:409\u001b[39m, in \u001b[36mOpenAI.complete\u001b[39m\u001b[34m(self, prompt, formatted, **kwargs)\u001b[39m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    408\u001b[39m     complete_fn = \u001b[38;5;28mself\u001b[39m._complete\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplete_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\llama_index\\core\\base\\llms\\generic_utils.py:184\u001b[39m, in \u001b[36mchat_to_completion_decorator.<locals>.wrapper\u001b[39m\u001b[34m(prompt, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, **kwargs: Any) -> CompletionResponse:\n\u001b[32m    182\u001b[39m     \u001b[38;5;66;03m# normalize input\u001b[39;00m\n\u001b[32m    183\u001b[39m     messages = prompt_to_messages(prompt)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     chat_response = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# normalize output\u001b[39;00m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_response_to_completion_response(chat_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:110\u001b[39m, in \u001b[36mllm_retry_decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m    103\u001b[39m retry = create_retry_decorator(\n\u001b[32m    104\u001b[39m     max_retries=max_retries,\n\u001b[32m    105\u001b[39m     random_exponential=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    108\u001b[39m     max_seconds=\u001b[32m20\u001b[39m,\n\u001b[32m    109\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\tenacity\\__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:480\u001b[39m, in \u001b[36mOpenAI._chat\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m    474\u001b[39m message_dicts = to_openai_message_dicts(\n\u001b[32m    475\u001b[39m     messages,\n\u001b[32m    476\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    477\u001b[39m )\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reuse_client:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    486\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m client:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "qa_dataset_groq = generate_question_context_pairs(nodes[0:3], llm=groq, num_questions_per_chunk=2, \n",
    "                                                  qa_generate_prompt_tmpl=DEFAULT_QA_GENERATE_PROMPT_TMPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'36536694-f7c2-40f1-b632-ddc8acc51487': \"What was the primary input method for programs on the IBM 1401, and what limitations did this pose for the author's early programming endeavors?\",\n",
       " 'ac57244c-0a0a-436a-bb02-eab7fd6e1a89': \"What two influences are mentioned in the text as having sparked the author's interest in pursuing Artificial Intelligence (AI) as a field of study?\",\n",
       " '7062e6d4-f442-482f-81a6-5f5040758c16': 'What was the primary reason the author was drawn to learning Lisp, and how did it expand their concept of a program?',\n",
       " '0530b143-e791-4197-afa3-7345ea93cd74': 'What realization did the author come to during their first year of graduate school regarding the state of Artificial Intelligence at the time, and what implications did this have for their future plans?',\n",
       " '00ca0e9f-b720-4bde-8c22-102627c23a3f': 'What motivated the author to consider a career in art, and what realization did they have while visiting the Carnegie Institute?',\n",
       " '133d4da1-4ada-4330-b9c6-aa97d5f5b928': 'What topic did the author choose for their dissertation, and what alternative topic do they retrospectively think they should have chosen?'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset_groq.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1703533589258,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "i9sidRY0xNz-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Describe the author's initial experiences with programming on the IBM 1401. What were some of the challenges he faced and how did the advent of microcomputers change his approach to programming?\"]\n"
     ]
    }
   ],
   "source": [
    "queries = qa_dataset.queries.values()\n",
    "print(list(queries)[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1703533589258,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "ecH5iAUrTaAW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1703533589258,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "mm5GCNZoriDu"
   },
   "outputs": [],
   "source": [
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1703533589258,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "Yb5p06r0xYOR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Query: Describe the author's initial experiences with programming on the IBM 1401. What were some of the challenges he faced and how did the advent of microcomputers change his approach to programming?\n",
      "Metrics: {'mrr': 1.0, 'hit_rate': 1.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try it out on a sample query\n",
    "sample_id, sample_query = list(qa_dataset.queries.items())[0]\n",
    "sample_expected = qa_dataset.relevant_docs[sample_id]\n",
    "\n",
    "eval_result = retriever_evaluator.evaluate(sample_query, sample_expected)\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1703533589258,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "MF4-RWsDrnMJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# try it out on an entire dataset\n",
    "eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1703533589259,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "mxiNl6TurpZQ"
   },
   "outputs": [],
   "source": [
    "def display_results(name, eval_results):\n",
    "    \"\"\"Display results from evaluate.\"\"\"\n",
    "\n",
    "    metric_dicts = []\n",
    "    for eval_result in eval_results:\n",
    "        metric_dict = eval_result.metric_vals_dict\n",
    "        metric_dicts.append(metric_dict)\n",
    "\n",
    "    full_df = pd.DataFrame(metric_dicts)\n",
    "\n",
    "    hit_rate = full_df[\"hit_rate\"].mean()\n",
    "    mrr = full_df[\"mrr\"].mean()\n",
    "\n",
    "    metric_df = pd.DataFrame(\n",
    "        {\"retrievers\": [name], \"hit_rate\": [hit_rate], \"mrr\": [mrr]}\n",
    "    )\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1703533589259,
     "user": {
      "displayName": "Ravi Theja",
      "userId": "12148656718425770960"
     },
     "user_tz": -330
    },
    "id": "yZeIaMWKrsY1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top-2 eval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retrievers  hit_rate  mrr\n",
       "0  top-2 eval       1.0  1.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_results(\"top-2 eval\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1Vz-YEkERI6dTLTUw-LUXAXBmBaGdm57M",
     "timestamp": 1703327875697
    },
    {
     "file_id": "19NSJbAey3PHdKo6HjKXxSG-eIIFUKhdU",
     "timestamp": 1701013745378
    }
   ]
  },
  "kernelspec": {
   "display_name": ".training-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
