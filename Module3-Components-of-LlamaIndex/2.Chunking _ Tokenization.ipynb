{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5095aed",
   "metadata": {},
   "source": [
    "## Content\n",
    "- How do you choose the right chunk size for your use case?\n",
    "- Chunkviz app https://chunkviz.up.railway.app/ \n",
    "- Subword Tokenization  isa a new techinique in LLM whch is different technic from NLP.\n",
    "- Differnet types of subwork tokenization - Byte Pair encoding, WordPiece and SentencePiece.\n",
    "- Tokenization Estimation website - https://platform.openai.com/tokenizer \n",
    "- Why is it important to know the total number of tokens in a chunk or document in RAG system?\n",
    "- Embedding models, their pricing and their token size\n",
    "- Text Generation models, their pricing and their token size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "292057aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from dotenv) (1.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-readers-file in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (0.5.2)\n",
      "Collecting llama-index-readers-web\n",
      "  Downloading llama_index_readers_web-0.5.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-readers-file) (4.13.5)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-readers-file) (0.7.1)\n",
      "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-readers-file) (0.13.3)\n",
      "Requirement already satisfied: pandas<2.3.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-readers-file) (2.2.3)\n",
      "Requirement already satisfied: pypdf<7,>=5.1.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-readers-file) (6.0.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-readers-file) (0.0.26)\n",
      "Requirement already satisfied: aiohttp<4,>=3.9.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-readers-web) (3.12.15)\n",
      "Collecting chromedriver-autoinstaller<0.7,>=0.6.3 (from llama-index-readers-web)\n",
      "  Using cached chromedriver_autoinstaller-0.6.4-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting html2text<2025,>=2024.2.26 (from llama-index-readers-web)\n",
      "  Using cached html2text-2024.2.26-py3-none-any.whl\n",
      "Requirement already satisfied: httpx>=0.28.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-readers-web) (0.28.1)\n",
      "Collecting lxml-html-clean>=0.4.2 (from llama-index-readers-web)\n",
      "  Using cached lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting lxml>=5.4.0 (from llama-index-readers-web)\n",
      "  Using cached lxml-6.0.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting markdownify>=1.1.0 (from llama-index-readers-web)\n",
      "  Using cached markdownify-1.2.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting newspaper3k<0.3,>=0.2.8 (from llama-index-readers-web)\n",
      "  Using cached newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oxylabs>=2.0.0 (from llama-index-readers-web)\n",
      "  Using cached oxylabs-2.0.0-py3-none-any.whl.metadata (687 bytes)\n",
      "Collecting playwright<2.0,>=1.30 (from llama-index-readers-web)\n",
      "  Downloading playwright-1.55.0-py3-none-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2.31.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-readers-web) (2.32.5)\n",
      "Collecting selenium<5,>=4.17.2 (from llama-index-readers-web)\n",
      "  Using cached selenium-4.35.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting spider-client<0.0.28,>=0.0.27 (from llama-index-readers-web)\n",
      "  Using cached spider_client-0.0.27-py3-none-any.whl\n",
      "Requirement already satisfied: urllib3>=1.1.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-readers-web) (2.5.0)\n",
      "Requirement already satisfied: charset-normalizer in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from unstructured) (3.4.3)\n",
      "Requirement already satisfied: filetype in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: nltk in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from unstructured) (3.9.1)\n",
      "Collecting emoji (from unstructured)\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from unstructured) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Using cached python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from unstructured) (2.3.2)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.14.0-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from unstructured) (4.15.0)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Using cached unstructured_client-0.42.3-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: wrapt in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from unstructured) (1.17.3)\n",
      "Requirement already satisfied: tqdm in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from unstructured) (4.67.1)\n",
      "Requirement already satisfied: psutil in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from unstructured) (7.0.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Using cached python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from aiohttp<4,>=3.9.1->llama-index-readers-web) (1.20.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file) (2.8)\n",
      "Requirement already satisfied: packaging>=23.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from chromedriver-autoinstaller<0.7,>=0.6.3->llama-index-readers-web) (25.0)\n",
      "Requirement already satisfied: anyio in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from httpx>=0.28.1->llama-index-readers-web) (4.10.0)\n",
      "Requirement already satisfied: certifi in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from httpx>=0.28.1->llama-index-readers-web) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from httpx>=0.28.1->llama-index-readers-web) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from httpx>=0.28.1->llama-index-readers-web) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from httpcore==1.*->httpx>=0.28.1->llama-index-readers-web) (0.16.0)\n",
      "Requirement already satisfied: aiosqlite in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2.2.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2025.7.0)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.3.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (3.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (11.3.0)\n",
      "Requirement already satisfied: platformdirs in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (4.4.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (6.0.2)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2.0.43)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.9.0)\n",
      "Requirement already satisfied: six<2,>=1.15 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from markdownify>=1.1.0->llama-index-readers-web) (1.17.0)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Using cached cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Using cached feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Using cached tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Using cached feedfinder2-0.0.4-py3-none-any.whl\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Using cached jieba3k-0.35.1-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Using cached tinysegmenter-0.3-py3-none-any.whl\n",
      "Requirement already satisfied: click in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from nltk->unstructured) (8.2.1)\n",
      "Requirement already satisfied: joblib in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from nltk->unstructured) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from nltk->unstructured) (2025.7.34)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pandas<2.3.0->llama-index-readers-file) (2025.2)\n",
      "Collecting pyee<14,>=13 (from playwright<2.0,>=1.30->llama-index-readers-web)\n",
      "  Using cached pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from playwright<2.0,>=1.30->llama-index-readers-web) (3.2.4)\n",
      "Collecting trio~=0.30.0 (from selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Using cached trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.12.2 (from selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Using cached trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting typing-extensions (from unstructured)\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting websocket-client~=1.8.0 (from selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: colorama in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from tqdm->unstructured) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from dataclasses-json->unstructured) (3.26.1)\n",
      "Collecting webencodings (from html5lib->unstructured)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Using cached olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured)\n",
      "  Using cached cryptography-45.0.6-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from unstructured-client->unstructured)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: griffe in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.13.0)\n",
      "Requirement already satisfied: jinja2 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (3.1.6)\n",
      "Collecting cffi>=1.14 (from cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Using cached sgmllib3k-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.4.1)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Using cached requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting filelock>=3.0.8 (from tldextract>=2.0.1->newspaper3k<0.3,>=0.2.8->llama-index-readers-web)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting sortedcontainers (from trio~=0.30.0->selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.30.0->selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from trio~=0.30.0->selenium<5,>=4.17.2->llama-index-readers-web) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.1.0)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3.0,>=2.5.0->selenium<5,>=4.17.2->llama-index-readers-web)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\training\\faa-training\\beyond-the-prompt-practical-rag-for-real-world-ai\\rag-systems-using-llamaindex\\rag-system-using-lamaindex\\.training-env\\lib\\site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (3.0.2)\n",
      "Downloading llama_index_readers_web-0.5.1-py3-none-any.whl (108 kB)\n",
      "Downloading unstructured-0.18.14-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 5.7 MB/s eta 0:00:00\n",
      "Using cached chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
      "Using cached lxml-6.0.1-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "Using cached lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached markdownify-1.2.0-py3-none-any.whl (15 kB)\n",
      "Using cached newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "Using cached oxylabs-2.0.0-py3-none-any.whl (34 kB)\n",
      "Downloading playwright-1.55.0-py3-none-win_amd64.whl (35.5 MB)\n",
      "   ---------------------------------------- 0.0/35.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/35.5 MB 5.6 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.1/35.5 MB 5.3 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.4/35.5 MB 5.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 4.5/35.5 MB 5.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 5.8/35.5 MB 5.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 7.1/35.5 MB 5.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 8.1/35.5 MB 5.7 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 9.4/35.5 MB 5.7 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 10.5/35.5 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 11.8/35.5 MB 5.8 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 13.1/35.5 MB 5.7 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 14.2/35.5 MB 5.7 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 15.5/35.5 MB 5.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 16.8/35.5 MB 5.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 17.8/35.5 MB 5.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 19.1/35.5 MB 5.6 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 20.2/35.5 MB 5.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 21.5/35.5 MB 5.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 22.8/35.5 MB 5.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 23.9/35.5 MB 5.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 24.9/35.5 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 26.2/35.5 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 27.3/35.5 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 28.6/35.5 MB 5.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 29.6/35.5 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 30.7/35.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 32.0/35.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 33.0/35.5 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 34.3/35.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  35.4/35.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 35.5/35.5 MB 5.3 MB/s eta 0:00:00\n",
      "Using cached selenium-4.35.0-py3-none-any.whl (9.6 MB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Using cached python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Using cached python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.14.0-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.0/1.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 5.0 MB/s eta 0:00:00\n",
      "Using cached unstructured_client-0.42.3-py3-none-any.whl (207 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached cryptography-45.0.6-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "Using cached cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
      "Using cached feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Using cached pyee-13.0.0-py3-none-any.whl (15 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
      "Using cached trio-0.30.0-py3-none-any.whl (499 kB)\n",
      "Using cached trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: webencodings, tinysegmenter, sortedcontainers, sgmllib3k, jieba3k, wsproto, websocket-client, typing-extensions, rapidfuzz, python-magic, python-iso639, pysocks, pycparser, outcome, olefile, lxml, langdetect, html5lib, html2text, filelock, feedparser, emoji, cssselect, chromedriver-autoinstaller, backoff, aiofiles, spider-client, requests-toolbelt, requests-file, python-oxmsg, pyee, lxml-html-clean, cffi, trio, tldextract, playwright, markdownify, feedfinder2, cryptography, unstructured-client, trio-websocket, oxylabs, newspaper3k, unstructured, selenium, llama-index-readers-web\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.15.0\n",
      "    Uninstalling typing_extensions-4.15.0:\n",
      "      Successfully uninstalled typing_extensions-4.15.0\n",
      "Successfully installed aiofiles-24.1.0 backoff-2.2.1 cffi-1.17.1 chromedriver-autoinstaller-0.6.4 cryptography-45.0.6 cssselect-1.3.0 emoji-2.14.1 feedfinder2-0.0.4 feedparser-6.0.11 filelock-3.19.1 html2text-2024.2.26 html5lib-1.1 jieba3k-0.35.1 langdetect-1.0.9 llama-index-readers-web-0.5.1 lxml-6.0.1 lxml-html-clean-0.4.2 markdownify-1.2.0 newspaper3k-0.2.8 olefile-0.47 outcome-1.3.0.post0 oxylabs-2.0.0 playwright-1.55.0 pycparser-2.22 pyee-13.0.0 pysocks-1.7.1 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.14.0 requests-file-2.1.0 requests-toolbelt-1.0.0 selenium-4.35.0 sgmllib3k-1.0.0 sortedcontainers-2.4.0 spider-client-0.0.27 tinysegmenter-0.3 tldextract-5.3.0 trio-0.30.0 trio-websocket-0.12.2 typing-extensions-4.14.1 unstructured-0.18.14 unstructured-client-0.42.3 webencodings-0.5.1 websocket-client-1.8.0 wsproto-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install dotenv\n",
    "!pip install llama-index-readers-file llama-index-readers-web unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bedd515-f8dc-4951-a90d-ba496cc384d2",
   "metadata": {},
   "source": [
    "# Chunking and Token Counting Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c4f745-8d76-4e0e-93d1-a7029d1441b6",
   "metadata": {
    "id": "cKlax-updNW-"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f3e966e-8b0a-4672-9bd9-dd7d04b42f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c07b0c62-a74d-4300-b2c3-bbb01ee62e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('D:/Training/FAA-Training/Beyond-the-Prompt-Practical-RAG-for-Real-World-AI/RAG-systems-using-LlamaIndex/RAG-System-Using-LamaIndex/.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c190e18-f4d6-4926-96d2-d8e960726948",
   "metadata": {},
   "source": [
    "### File Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78b05010-f04c-42cc-b620-d74127af3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter, TokenTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773c3d9-7547-40f3-b1a4-e274a5f609cf",
   "metadata": {},
   "source": [
    "https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9ae0b98-43d6-4d49-9778-171de9c6f406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Training\\FAA-Training\\Beyond-the-Prompt-Practical-RAG-for-Real-World-AI\\RAG-systems-using-LlamaIndex\\RAG-System-Using-LamaIndex\\.training-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading files: 100%|██████████| 1/1 [00:04<00:00,  4.51s/it]\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(input_files=[\"./data/paul_graham_essay.txt\"], filename_as_id=True).load_data(show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70194e91-5e75-4174-a6e2-ff69d55ca638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04b5c727-af59-4bc2-b56b-bc8db086c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15c31d24-b992-47f2-85d7-fcf2af95d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93e4e5df-d923-4ad1-a839-d8a03de80edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41051f44-2637-43f2-9510-ad63235791cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='43a92da0-b8ce-4270-8465-8f051270298d', embedding=None, metadata={'file_path': 'data\\\\paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2025-08-28', 'last_modified_date': '2024-06-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='data\\\\paul_graham_essay.txt', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'data\\\\paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2025-08-28', 'last_modified_date': '2024-06-11'}, hash='f27647b46b4c5a7840058b929ffe86da313fba6fa125bb9b3537dc3242e71296'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5a8e7c32-9f00-4c50-9fac-d834fb2d5b57', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='2b076feb45ef9318654997e47fb3b2f2185bcc7e39e0997045fcf755cb2ca6dc')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='What I Worked On\\n\\nFebruary 2021\\n\\nBefore college the two main things I worked on, outside of school, were writing and programming. I didn\\'t write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\\n\\nThe first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district\\'s 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain\\'s lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\\n\\nThe language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\\n\\nI was puzzled by the 1401. I couldn\\'t figure out what to do with it. And in retrospect there\\'s not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn\\'t have any data stored on punched cards. The only other option was to do things that didn\\'t rely on any input, like calculate approximations of pi, but I didn\\'t know enough math to do anything interesting of that type. So I\\'m not surprised I can\\'t remember any programs I wrote, because they can\\'t have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn\\'t. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager\\'s expression made clear.\\n\\nWith microcomputers, everything changed. Now you could have a computer sitting right in front of you, on a desk, that could respond to your keystrokes as it was running instead of just churning through a stack of punch cards and then stopping. [1]\\n\\nThe first of my friends to get a microcomputer built it himself. It was sold as a kit by Heathkit. I remember vividly how impressed and envious I felt watching him sitting in front of it, typing programs right into the computer.\\n\\nComputers were expensive in those days and it took me years of nagging before I convinced my father to buy one, a TRS-80, in about 1980. The gold standard then was the Apple II, but a TRS-80 was good enough. This was when I really started programming. I wrote simple games, a program to predict how high my model rockets would fly, and a word processor that my father used to write at least one book. There was only room in memory for about 2 pages of text, so he\\'d write 2 pages at a time and then print them out, but it was a lot better than a typewriter.\\n\\nThough I liked programming, I didn\\'t plan to study it in college. In college I was going to study philosophy, which sounded much more powerful. It seemed, to my naive high school self, to be the study of the ultimate truths, compared to which the things studied in other fields would be mere domain knowledge. What I discovered when I got to college was that the other fields took up so much of the space of ideas that there wasn\\'t much left for these supposed ultimate truths. All that seemed left for philosophy were edge cases that people in other fields felt could safely be ignored.\\n\\nI couldn\\'t have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\\n\\nAI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven\\'t tried rereading The Moon is a Harsh Mistress, so I don\\'t know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we\\'d have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most.', mimetype='text/plain', start_char_idx=2, end_char_idx=4320, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee415d86-b5d0-43cf-9cdf-0d22dea9e3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': 'data\\\\paul_graham_essay.txt',\n",
       " 'file_name': 'paul_graham_essay.txt',\n",
       " 'file_type': 'text/plain',\n",
       " 'file_size': 75042,\n",
       " 'creation_date': '2025-08-28',\n",
       " 'last_modified_date': '2024-06-11'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6e0a019-a126-4bac-b152-3880f4e63133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What I Worked On\n",
      "\n",
      "February 2021\n",
      "\n",
      "Before college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n",
      "\n",
      "The first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district's 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain's lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\n",
      "\n",
      "The language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\n",
      "\n",
      "I was puzzled by the 1401. I couldn't figure out what to do with it. And in retrospect there's not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn't have any data stored on punched cards. The only other option was to do things that didn't rely on any input, like calculate approximations of pi, but I didn't know enough math to do anything interesting of that type. So I'm not surprised I can't remember any programs I wrote, because they can't have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn't. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager's expression made clear.\n",
      "\n",
      "With microcomputers, everything changed. Now you could have a computer sitting right in front of you, on a desk, that could respond to your keystrokes as it was running instead of just churning through a stack of punch cards and then stopping. [1]\n",
      "\n",
      "The first of my friends to get a microcomputer built it himself. It was sold as a kit by Heathkit. I remember vividly how impressed and envious I felt watching him sitting in front of it, typing programs right into the computer.\n",
      "\n",
      "Computers were expensive in those days and it took me years of nagging before I convinced my father to buy one, a TRS-80, in about 1980. The gold standard then was the Apple II, but a TRS-80 was good enough. This was when I really started programming. I wrote simple games, a program to predict how high my model rockets would fly, and a word processor that my father used to write at least one book. There was only room in memory for about 2 pages of text, so he'd write 2 pages at a time and then print them out, but it was a lot better than a typewriter.\n",
      "\n",
      "Though I liked programming, I didn't plan to study it in college. In college I was going to study philosophy, which sounded much more powerful. It seemed, to my naive high school self, to be the study of the ultimate truths, compared to which the things studied in other fields would be mere domain knowledge. What I discovered when I got to college was that the other fields took up so much of the space of ideas that there wasn't much left for these supposed ultimate truths. All that seemed left for philosophy were edge cases that people in other fields felt could safely be ignored.\n",
      "\n",
      "I couldn't have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\n",
      "\n",
      "AI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven't tried rereading The Moon is a Harsh Mistress, so I don't know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we'd have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most.\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "978f8a84-034f-49b6-87ee-87b7cd1f283b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens in node 1 - 967\n",
      "number of tokens in node 2 - 963\n",
      "number of tokens in node 3 - 975\n",
      "number of tokens in node 4 - 949\n",
      "number of tokens in node 5 - 947\n",
      "number of tokens in node 6 - 949\n",
      "number of tokens in node 7 - 942\n",
      "number of tokens in node 8 - 973\n",
      "number of tokens in node 9 - 965\n",
      "number of tokens in node 10 - 967\n",
      "number of tokens in node 11 - 966\n",
      "number of tokens in node 12 - 969\n",
      "number of tokens in node 13 - 958\n",
      "number of tokens in node 14 - 972\n",
      "number of tokens in node 15 - 954\n",
      "number of tokens in node 16 - 960\n",
      "number of tokens in node 17 - 981\n",
      "number of tokens in node 18 - 326\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "for i, node in enumerate(nodes):\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    print(f'number of tokens in node {i+1} - {len(encoding.encode(node.text))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a1829fb-40bc-458c-a6aa-ad25ddfbd364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What I Worked On\n",
      "\n",
      "February 2021\n",
      "\n",
      "Before college the two main things I worked on, outside of school, were writing and programming. I didn't write essays. I wrote what beginning writers were supposed to write then, and probably still are: short stories. My stories were awful. They had hardly any plot, just characters with strong feelings, which I imagined made them deep.\n",
      "\n",
      "The first programs I tried writing were on the IBM 1401 that our school district used for what was then called \"data processing.\" This was in 9th grade, so I was 13 or 14. The school district's 1401 happened to be in the basement of our junior high school, and my friend Rich Draves and I got permission to use it. It was like a mini Bond villain's lair down there, with all these alien-looking machines — CPU, disk drives, printer, card reader — sitting up on a raised floor under bright fluorescent lights.\n",
      "\n",
      "The language we used was an early version of Fortran. You had to type programs on punch cards, then stack them in the card reader and press a button to load the program into memory and run it. The result would ordinarily be to print something on the spectacularly loud printer.\n",
      "\n",
      "I was puzzled by the 1401. I couldn't figure out what to do with it. And in retrospect there's not much I could have done with it. The only form of input to programs was data stored on punched cards, and I didn't have any data stored on punched cards. The only other option was to do things that didn't rely on any input, like calculate approximations of pi, but I didn't know enough math to do anything interesting of that type. So I'm not surprised I can't remember any programs I wrote, because they can't have done much. My clearest memory is of the moment I learned it was possible for programs not to terminate, when one of mine didn't. On a machine without time-sharing, this was a social as well as a technical error, as the data center manager's expression made clear.\n",
      "\n",
      "With microcomputers, everything changed. Now you could have a computer sitting right in front of you, on a desk, that could respond to your keystrokes as it was running instead of just churning through a stack of punch cards and then stopping. [1]\n",
      "\n",
      "The first of my friends to get a microcomputer built it himself. It was sold as a kit by Heathkit. I remember vividly how impressed and envious I felt watching him sitting in front of it, typing programs right into the computer.\n",
      "\n",
      "Computers were expensive in those days and it took me years of nagging before I convinced my father to buy one, a TRS-80, in about 1980. The gold standard then was the Apple II, but a TRS-80 was good enough. This was when I really started programming. I wrote simple games, a program to predict how high my model rockets would fly, and a word processor that my father used to write at least one book. There was only room in memory for about 2 pages of text, so he'd write 2 pages at a time and then print them out, but it was a lot better than a typewriter.\n",
      "\n",
      "Though I liked programming, I didn't plan to study it in college. In college I was going to study philosophy, which sounded much more powerful. It seemed, to my naive high school self, to be the study of the ultimate truths, compared to which the things studied in other fields would be mere domain knowledge. What I discovered when I got to college was that the other fields took up so much of the space of ideas that there wasn't much left for these supposed ultimate truths. All that seemed left for philosophy were edge cases that people in other fields felt could safely be ignored.\n",
      "\n",
      "I couldn't have put this into words when I was 18. All I knew at the time was that I kept taking philosophy courses and they kept being boring. So I decided to switch to AI.\n",
      "\n",
      "AI was in the air in the mid 1980s, but there were two things especially that made me want to work on it: a novel by Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike, and a PBS documentary that showed Terry Winograd using SHRDLU. I haven't tried rereading The Moon is a Harsh Mistress, so I don't know how well it has aged, but when I read it I was drawn entirely into its world. It seemed only a matter of time before we'd have Mike, and when I saw Winograd using SHRDLU, it seemed like that time would be a few years at most.\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99093c07-4984-4874-982e-1af471644404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3923,\n",
       " 358,\n",
       " 5664,\n",
       " 291,\n",
       " 1952,\n",
       " 271,\n",
       " 33877,\n",
       " 220,\n",
       " 2366,\n",
       " 16,\n",
       " 271,\n",
       " 10438,\n",
       " 7926,\n",
       " 279,\n",
       " 1403,\n",
       " 1925,\n",
       " 2574,\n",
       " 358,\n",
       " 6575,\n",
       " 389,\n",
       " 11,\n",
       " 4994,\n",
       " 315,\n",
       " 2978,\n",
       " 11,\n",
       " 1051,\n",
       " 4477,\n",
       " 323,\n",
       " 15840,\n",
       " 13,\n",
       " 358,\n",
       " 3287,\n",
       " 956,\n",
       " 3350,\n",
       " 23691,\n",
       " 13,\n",
       " 358,\n",
       " 6267,\n",
       " 1148,\n",
       " 7314,\n",
       " 16483,\n",
       " 1051,\n",
       " 10171,\n",
       " 311,\n",
       " 3350,\n",
       " 1243,\n",
       " 11,\n",
       " 323,\n",
       " 4762,\n",
       " 2103,\n",
       " 527,\n",
       " 25,\n",
       " 2875,\n",
       " 7493,\n",
       " 13,\n",
       " 3092,\n",
       " 7493,\n",
       " 1051,\n",
       " 25629,\n",
       " 13,\n",
       " 2435,\n",
       " 1047,\n",
       " 20781,\n",
       " 904,\n",
       " 7234,\n",
       " 11,\n",
       " 1120,\n",
       " 5885,\n",
       " 449,\n",
       " 3831,\n",
       " 16024,\n",
       " 11,\n",
       " 902,\n",
       " 358,\n",
       " 35706,\n",
       " 1903,\n",
       " 1124,\n",
       " 5655,\n",
       " 382,\n",
       " 791,\n",
       " 1176,\n",
       " 7620,\n",
       " 358,\n",
       " 6818,\n",
       " 4477,\n",
       " 1051,\n",
       " 389,\n",
       " 279,\n",
       " 29022,\n",
       " 220,\n",
       " 6860,\n",
       " 16,\n",
       " 430,\n",
       " 1057,\n",
       " 2978,\n",
       " 9474,\n",
       " 1511,\n",
       " 369,\n",
       " 1148,\n",
       " 574,\n",
       " 1243,\n",
       " 2663,\n",
       " 330,\n",
       " 695,\n",
       " 8863,\n",
       " 1210,\n",
       " 1115,\n",
       " 574,\n",
       " 304,\n",
       " 220,\n",
       " 24,\n",
       " 339,\n",
       " 12239,\n",
       " 11,\n",
       " 779,\n",
       " 358,\n",
       " 574,\n",
       " 220,\n",
       " 1032,\n",
       " 477,\n",
       " 220,\n",
       " 975,\n",
       " 13,\n",
       " 578,\n",
       " 2978,\n",
       " 9474,\n",
       " 596,\n",
       " 220,\n",
       " 6860,\n",
       " 16,\n",
       " 7077,\n",
       " 311,\n",
       " 387,\n",
       " 304,\n",
       " 279,\n",
       " 31741,\n",
       " 315,\n",
       " 1057,\n",
       " 27144,\n",
       " 1579,\n",
       " 2978,\n",
       " 11,\n",
       " 323,\n",
       " 856,\n",
       " 4333,\n",
       " 8269,\n",
       " 2999,\n",
       " 4798,\n",
       " 323,\n",
       " 358,\n",
       " 2751,\n",
       " 8041,\n",
       " 311,\n",
       " 1005,\n",
       " 433,\n",
       " 13,\n",
       " 1102,\n",
       " 574,\n",
       " 1093,\n",
       " 264,\n",
       " 13726,\n",
       " 24537,\n",
       " 40148,\n",
       " 596,\n",
       " 1208,\n",
       " 404,\n",
       " 1523,\n",
       " 1070,\n",
       " 11,\n",
       " 449,\n",
       " 682,\n",
       " 1521,\n",
       " 20167,\n",
       " 31348,\n",
       " 12933,\n",
       " 2001,\n",
       " 14266,\n",
       " 11,\n",
       " 13668,\n",
       " 20722,\n",
       " 11,\n",
       " 23185,\n",
       " 11,\n",
       " 3786,\n",
       " 6742,\n",
       " 2001,\n",
       " 11961,\n",
       " 709,\n",
       " 389,\n",
       " 264,\n",
       " 9408,\n",
       " 6558,\n",
       " 1234,\n",
       " 10107,\n",
       " 74864,\n",
       " 13001,\n",
       " 382,\n",
       " 791,\n",
       " 4221,\n",
       " 584,\n",
       " 1511,\n",
       " 574,\n",
       " 459,\n",
       " 4216,\n",
       " 2373,\n",
       " 315,\n",
       " 11246,\n",
       " 6713,\n",
       " 13,\n",
       " 1472,\n",
       " 1047,\n",
       " 311,\n",
       " 955,\n",
       " 7620,\n",
       " 389,\n",
       " 21004,\n",
       " 7563,\n",
       " 11,\n",
       " 1243,\n",
       " 5729,\n",
       " 1124,\n",
       " 304,\n",
       " 279,\n",
       " 3786,\n",
       " 6742,\n",
       " 323,\n",
       " 3577,\n",
       " 264,\n",
       " 3215,\n",
       " 311,\n",
       " 2865,\n",
       " 279,\n",
       " 2068,\n",
       " 1139,\n",
       " 5044,\n",
       " 323,\n",
       " 1629,\n",
       " 433,\n",
       " 13,\n",
       " 578,\n",
       " 1121,\n",
       " 1053,\n",
       " 98081,\n",
       " 387,\n",
       " 311,\n",
       " 1194,\n",
       " 2555,\n",
       " 389,\n",
       " 279,\n",
       " 28809,\n",
       " 398,\n",
       " 17813,\n",
       " 23185,\n",
       " 382,\n",
       " 40,\n",
       " 574,\n",
       " 87420,\n",
       " 555,\n",
       " 279,\n",
       " 220,\n",
       " 6860,\n",
       " 16,\n",
       " 13,\n",
       " 358,\n",
       " 7846,\n",
       " 956,\n",
       " 7216,\n",
       " 704,\n",
       " 1148,\n",
       " 311,\n",
       " 656,\n",
       " 449,\n",
       " 433,\n",
       " 13,\n",
       " 1628,\n",
       " 304,\n",
       " 77653,\n",
       " 1070,\n",
       " 596,\n",
       " 539,\n",
       " 1790,\n",
       " 358,\n",
       " 1436,\n",
       " 617,\n",
       " 2884,\n",
       " 449,\n",
       " 433,\n",
       " 13,\n",
       " 578,\n",
       " 1193,\n",
       " 1376,\n",
       " 315,\n",
       " 1988,\n",
       " 311,\n",
       " 7620,\n",
       " 574,\n",
       " 828,\n",
       " 9967,\n",
       " 389,\n",
       " 62018,\n",
       " 7563,\n",
       " 11,\n",
       " 323,\n",
       " 358,\n",
       " 3287,\n",
       " 956,\n",
       " 617,\n",
       " 904,\n",
       " 828,\n",
       " 9967,\n",
       " 389,\n",
       " 62018,\n",
       " 7563,\n",
       " 13,\n",
       " 578,\n",
       " 1193,\n",
       " 1023,\n",
       " 3072,\n",
       " 574,\n",
       " 311,\n",
       " 656,\n",
       " 2574,\n",
       " 430,\n",
       " 3287,\n",
       " 956,\n",
       " 17631,\n",
       " 389,\n",
       " 904,\n",
       " 1988,\n",
       " 11,\n",
       " 1093,\n",
       " 11294,\n",
       " 10049,\n",
       " 97476,\n",
       " 315,\n",
       " 9115,\n",
       " 11,\n",
       " 719,\n",
       " 358,\n",
       " 3287,\n",
       " 956,\n",
       " 1440,\n",
       " 3403,\n",
       " 7033,\n",
       " 311,\n",
       " 656,\n",
       " 4205,\n",
       " 7185,\n",
       " 315,\n",
       " 430,\n",
       " 955,\n",
       " 13,\n",
       " 2100,\n",
       " 358,\n",
       " 2846,\n",
       " 539,\n",
       " 14792,\n",
       " 358,\n",
       " 649,\n",
       " 956,\n",
       " 6227,\n",
       " 904,\n",
       " 7620,\n",
       " 358,\n",
       " 6267,\n",
       " 11,\n",
       " 1606,\n",
       " 814,\n",
       " 649,\n",
       " 956,\n",
       " 617,\n",
       " 2884,\n",
       " 1790,\n",
       " 13,\n",
       " 3092,\n",
       " 11551,\n",
       " 15795,\n",
       " 5044,\n",
       " 374,\n",
       " 315,\n",
       " 279,\n",
       " 4545,\n",
       " 358,\n",
       " 9687,\n",
       " 433,\n",
       " 574,\n",
       " 3284,\n",
       " 369,\n",
       " 7620,\n",
       " 539,\n",
       " 311,\n",
       " 30754,\n",
       " 11,\n",
       " 994,\n",
       " 832,\n",
       " 315,\n",
       " 10705,\n",
       " 3287,\n",
       " 956,\n",
       " 13,\n",
       " 1952,\n",
       " 264,\n",
       " 5780,\n",
       " 2085,\n",
       " 892,\n",
       " 55856,\n",
       " 11,\n",
       " 420,\n",
       " 574,\n",
       " 264,\n",
       " 3674,\n",
       " 439,\n",
       " 1664,\n",
       " 439,\n",
       " 264,\n",
       " 11156,\n",
       " 1493,\n",
       " 11,\n",
       " 439,\n",
       " 279,\n",
       " 828,\n",
       " 4219,\n",
       " 6783,\n",
       " 596,\n",
       " 7645,\n",
       " 1903,\n",
       " 2867,\n",
       " 382,\n",
       " 2409,\n",
       " 8162,\n",
       " 66047,\n",
       " 388,\n",
       " 11,\n",
       " 4395,\n",
       " 5614,\n",
       " 13,\n",
       " 4800,\n",
       " 499,\n",
       " 1436,\n",
       " 617,\n",
       " 264,\n",
       " 6500,\n",
       " 11961,\n",
       " 1314,\n",
       " 304,\n",
       " 4156,\n",
       " 315,\n",
       " 499,\n",
       " 11,\n",
       " 389,\n",
       " 264,\n",
       " 18496,\n",
       " 11,\n",
       " 430,\n",
       " 1436,\n",
       " 6013,\n",
       " 311,\n",
       " 701,\n",
       " 100232,\n",
       " 56137,\n",
       " 439,\n",
       " 433,\n",
       " 574,\n",
       " 4401,\n",
       " 4619,\n",
       " 315,\n",
       " 1120,\n",
       " 523,\n",
       " 54444,\n",
       " 1555,\n",
       " 264,\n",
       " 5729,\n",
       " 315,\n",
       " 21004,\n",
       " 7563,\n",
       " 323,\n",
       " 1243,\n",
       " 23351,\n",
       " 13,\n",
       " 510,\n",
       " 16,\n",
       " 2595,\n",
       " 791,\n",
       " 1176,\n",
       " 315,\n",
       " 856,\n",
       " 4885,\n",
       " 311,\n",
       " 636,\n",
       " 264,\n",
       " 8162,\n",
       " 44211,\n",
       " 5918,\n",
       " 433,\n",
       " 5678,\n",
       " 13,\n",
       " 1102,\n",
       " 574,\n",
       " 6216,\n",
       " 439,\n",
       " 264,\n",
       " 16530,\n",
       " 555,\n",
       " 48562,\n",
       " 8390,\n",
       " 13,\n",
       " 358,\n",
       " 6227,\n",
       " 43120,\n",
       " 398,\n",
       " 1268,\n",
       " 25408,\n",
       " 323,\n",
       " 665,\n",
       " 2528,\n",
       " 358,\n",
       " 6612,\n",
       " 10307,\n",
       " 1461,\n",
       " 11961,\n",
       " 304,\n",
       " 4156,\n",
       " 315,\n",
       " 433,\n",
       " 11,\n",
       " 20061,\n",
       " 7620,\n",
       " 1314,\n",
       " 1139,\n",
       " 279,\n",
       " 6500,\n",
       " 382,\n",
       " 59122,\n",
       " 388,\n",
       " 1051,\n",
       " 11646,\n",
       " 304,\n",
       " 1884,\n",
       " 2919,\n",
       " 323,\n",
       " 433,\n",
       " 3952,\n",
       " 757,\n",
       " 1667,\n",
       " 315,\n",
       " 37628,\n",
       " 3252,\n",
       " 1603,\n",
       " 358,\n",
       " 22954,\n",
       " 856,\n",
       " 7126,\n",
       " 311,\n",
       " 3780,\n",
       " 832,\n",
       " 11,\n",
       " 264,\n",
       " 5091,\n",
       " 50,\n",
       " 12,\n",
       " 1490,\n",
       " 11,\n",
       " 304,\n",
       " 922,\n",
       " 220,\n",
       " 3753,\n",
       " 15,\n",
       " 13,\n",
       " 578,\n",
       " 6761,\n",
       " 5410,\n",
       " 1243,\n",
       " 574,\n",
       " 279,\n",
       " 8325,\n",
       " 8105,\n",
       " 11,\n",
       " 719,\n",
       " 264,\n",
       " 5091,\n",
       " 50,\n",
       " 12,\n",
       " 1490,\n",
       " 574,\n",
       " 1695,\n",
       " 3403,\n",
       " 13,\n",
       " 1115,\n",
       " 574,\n",
       " 994,\n",
       " 358,\n",
       " 2216,\n",
       " 3940,\n",
       " 15840,\n",
       " 13,\n",
       " 358,\n",
       " 6267,\n",
       " 4382,\n",
       " 3953,\n",
       " 11,\n",
       " 264,\n",
       " 2068,\n",
       " 311,\n",
       " 7168,\n",
       " 1268,\n",
       " 1579,\n",
       " 856,\n",
       " 1646,\n",
       " 53098,\n",
       " 1053,\n",
       " 11722,\n",
       " 11,\n",
       " 323,\n",
       " 264,\n",
       " 3492,\n",
       " 18121,\n",
       " 430,\n",
       " 856,\n",
       " 7126,\n",
       " 1511,\n",
       " 311,\n",
       " 3350,\n",
       " 520,\n",
       " 3325,\n",
       " 832,\n",
       " 2363,\n",
       " 13,\n",
       " 2684,\n",
       " 574,\n",
       " 1193,\n",
       " 3130,\n",
       " 304,\n",
       " 5044,\n",
       " 369,\n",
       " 922,\n",
       " 220,\n",
       " 17,\n",
       " 6959,\n",
       " 315,\n",
       " 1495,\n",
       " 11,\n",
       " 779,\n",
       " 568,\n",
       " 4265,\n",
       " 3350,\n",
       " 220,\n",
       " 17,\n",
       " 6959,\n",
       " 520,\n",
       " 264,\n",
       " 892,\n",
       " 323,\n",
       " 1243,\n",
       " 1194,\n",
       " 1124,\n",
       " 704,\n",
       " 11,\n",
       " 719,\n",
       " 433,\n",
       " 574,\n",
       " 264,\n",
       " 2763,\n",
       " 2731,\n",
       " 1109,\n",
       " 264,\n",
       " 3666,\n",
       " 73580,\n",
       " 382,\n",
       " 27831,\n",
       " 358,\n",
       " 15262,\n",
       " 15840,\n",
       " 11,\n",
       " 358,\n",
       " 3287,\n",
       " 956,\n",
       " 3197,\n",
       " 311,\n",
       " 4007,\n",
       " 433,\n",
       " 304,\n",
       " 7926,\n",
       " 13,\n",
       " 763,\n",
       " 7926,\n",
       " 358,\n",
       " 574,\n",
       " 2133,\n",
       " 311,\n",
       " 4007,\n",
       " 19675,\n",
       " 11,\n",
       " 902,\n",
       " 35408,\n",
       " 1790,\n",
       " 810,\n",
       " 8147,\n",
       " 13,\n",
       " 1102,\n",
       " 9508,\n",
       " 11,\n",
       " 311,\n",
       " 856,\n",
       " 50765,\n",
       " 1579,\n",
       " 2978,\n",
       " 659,\n",
       " 11,\n",
       " 311,\n",
       " 387,\n",
       " 279,\n",
       " 4007,\n",
       " 315,\n",
       " 279,\n",
       " 17139,\n",
       " 53219,\n",
       " 11,\n",
       " 7863,\n",
       " 311,\n",
       " 902,\n",
       " 279,\n",
       " 2574,\n",
       " 20041,\n",
       " 304,\n",
       " 1023,\n",
       " 5151,\n",
       " 1053,\n",
       " 387,\n",
       " 17983,\n",
       " 8106,\n",
       " 6677,\n",
       " 13,\n",
       " 3639,\n",
       " 358,\n",
       " 11352,\n",
       " 994,\n",
       " 358,\n",
       " 2751,\n",
       " 311,\n",
       " 7926,\n",
       " 574,\n",
       " 430,\n",
       " 279,\n",
       " 1023,\n",
       " 5151,\n",
       " 3952,\n",
       " 709,\n",
       " 779,\n",
       " 1790,\n",
       " 315,\n",
       " 279,\n",
       " 3634,\n",
       " 315,\n",
       " 6848,\n",
       " 430,\n",
       " 1070,\n",
       " 5828,\n",
       " 956,\n",
       " 1790,\n",
       " 2163,\n",
       " 369,\n",
       " 1521,\n",
       " 10171,\n",
       " 17139,\n",
       " 53219,\n",
       " 13,\n",
       " 2052,\n",
       " 430,\n",
       " 9508,\n",
       " 2163,\n",
       " 369,\n",
       " 19675,\n",
       " 1051,\n",
       " 6964,\n",
       " 5157,\n",
       " 430,\n",
       " 1274,\n",
       " 304,\n",
       " 1023,\n",
       " 5151,\n",
       " 6612,\n",
       " 1436,\n",
       " 21676,\n",
       " 387,\n",
       " 12305,\n",
       " 382,\n",
       " 40,\n",
       " 7846,\n",
       " 956,\n",
       " 617,\n",
       " 2231,\n",
       " 420,\n",
       " 1139,\n",
       " 4339,\n",
       " 994,\n",
       " 358,\n",
       " 574,\n",
       " 220,\n",
       " 972,\n",
       " 13,\n",
       " 2052,\n",
       " 358,\n",
       " 7020,\n",
       " 520,\n",
       " 279,\n",
       " 892,\n",
       " 574,\n",
       " 430,\n",
       " 358,\n",
       " 8774,\n",
       " 4737,\n",
       " 19675,\n",
       " 14307,\n",
       " 323,\n",
       " 814,\n",
       " 8774,\n",
       " 1694,\n",
       " 28859,\n",
       " 13,\n",
       " 2100,\n",
       " 358,\n",
       " 6773,\n",
       " 311,\n",
       " 3480,\n",
       " 311,\n",
       " 15592,\n",
       " 382,\n",
       " 15836,\n",
       " 574,\n",
       " 304,\n",
       " 279,\n",
       " 3805,\n",
       " 304,\n",
       " 279,\n",
       " 5209,\n",
       " 220,\n",
       " 3753,\n",
       " 15,\n",
       " 82,\n",
       " 11,\n",
       " 719,\n",
       " 1070,\n",
       " 1051,\n",
       " 1403,\n",
       " 2574,\n",
       " 5423,\n",
       " 430,\n",
       " 1903,\n",
       " 757,\n",
       " 1390,\n",
       " 311,\n",
       " 990,\n",
       " 389,\n",
       " 433,\n",
       " 25,\n",
       " 264,\n",
       " 11775,\n",
       " 555,\n",
       " 64782,\n",
       " 79469,\n",
       " 2663,\n",
       " 578,\n",
       " 17781,\n",
       " 374,\n",
       " 264,\n",
       " 5340,\n",
       " 939,\n",
       " 97129,\n",
       " 11,\n",
       " 902,\n",
       " 15109,\n",
       " 459,\n",
       " 25530,\n",
       " 6500,\n",
       " 2663,\n",
       " 11519,\n",
       " 11,\n",
       " 323,\n",
       " 264,\n",
       " 60145,\n",
       " 25999,\n",
       " 430,\n",
       " 8710,\n",
       " 32618,\n",
       " 12468,\n",
       " 68011,\n",
       " 1701,\n",
       " 78148,\n",
       " 16931,\n",
       " 52,\n",
       " 13,\n",
       " 358,\n",
       " 9167,\n",
       " 956,\n",
       " 6818,\n",
       " 436,\n",
       " 486,\n",
       " 2277,\n",
       " 578,\n",
       " 17781,\n",
       " 374,\n",
       " 264,\n",
       " 5340,\n",
       " 939,\n",
       " 97129,\n",
       " 11,\n",
       " 779,\n",
       " 358,\n",
       " 1541,\n",
       " 956,\n",
       " 1440,\n",
       " 1268,\n",
       " 1664,\n",
       " 433,\n",
       " 706,\n",
       " 20330,\n",
       " 11,\n",
       " 719,\n",
       " 994,\n",
       " 358,\n",
       " 1373,\n",
       " 433,\n",
       " 358,\n",
       " 574,\n",
       " 15107,\n",
       " 11622,\n",
       " 1139,\n",
       " 1202,\n",
       " 1917,\n",
       " 13,\n",
       " 1102,\n",
       " 9508,\n",
       " 1193,\n",
       " 264,\n",
       " 5030,\n",
       " 315,\n",
       " 892,\n",
       " 1603,\n",
       " 584,\n",
       " 4265,\n",
       " 617,\n",
       " 11519,\n",
       " 11,\n",
       " 323,\n",
       " 994,\n",
       " 358,\n",
       " 5602,\n",
       " 12468,\n",
       " 68011,\n",
       " 1701,\n",
       " 78148,\n",
       " 16931,\n",
       " 52,\n",
       " 11,\n",
       " 433,\n",
       " 9508,\n",
       " 1093,\n",
       " 430,\n",
       " 892,\n",
       " 1053,\n",
       " 387,\n",
       " 264,\n",
       " 2478,\n",
       " 1667,\n",
       " 520,\n",
       " 1455,\n",
       " 13]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.encode(nodes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd594928-0e1e-4d7d-9312-3c87a77242ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.llms import ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1008ef11-df97-4bd6-b1ff-7ee758e10766",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bc0a3a8-7653-4d0c-b074-6b6efa05d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"answer the question accurately\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"why is the sky blue?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23e9a1e7-ae6f-4ed3-a249-92bb1d64bb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 23:27:12,634 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a209d45a-52f5-431c-b890-07463d4d024a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The sky appears blue due to a phenomenon called Rayleigh scattering. When sunlight enters the Earth's atmosphere, it collides with molecules and small particles in the air. Sunlight is made up of different colors, each with varying wavelengths. Blue light has a shorter wavelength and is scattered in all directions more than other colors with longer wavelengths, such as red or yellow. As a result, when we look up at the sky during the day, we see more of the scattered blue light, making the sky appear blue.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4dba0900-9cff-492d-afd1-00f434259465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C9b9ySSkCQKNy5sj83UXfyud7ta6p', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The sky appears blue due to a phenomenon called Rayleigh scattering. When sunlight enters the Earth's atmosphere, it collides with molecules and small particles in the air. Sunlight is made up of different colors, each with varying wavelengths. Blue light has a shorter wavelength and is scattered in all directions more than other colors with longer wavelengths, such as red or yellow. As a result, when we look up at the sky during the day, we see more of the scattered blue light, making the sky appear blue.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1756403830, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=102, prompt_tokens=21, total_tokens=123, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "924d7555-2a7a-4d50-80be-392e92467c07",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ChatCompletion' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43musage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.dict()\n",
      "\u001b[31mTypeError\u001b[39m: 'ChatCompletion' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "response.raw['usage'].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7869e9f1-9ad9-4e4e-a390-6562008e08aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(response.message.content))   # totak number of tokens in the output/response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0eb1480b-b934-4dce-a10a-90f122803126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.message.content)  # number of characters in the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0fbe3f-56f7-43eb-906f-ce3f83aa5c65",
   "metadata": {},
   "source": [
    "## Gettting the Token IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855eb0b7-baab-410d-ab23-61b7f2df9a13",
   "metadata": {},
   "source": [
    "**By default, LlamaIndex uses a global tokenizer for all token counting. This defaults to `cl100k` from tiktoken, which is the tokenizer to match the default LLM `gpt-3.5-turbo.`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d54f5176-301f-4f35-8459-ad1b6566b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb536773-1a14-475f-9ac0-6c36a4407897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15339, 1917, 0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\"hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4881e371-299a-4412-84ae-532bd8a90cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text: str, encoding_name: str) -> int:\n",
    "    \"\"\"Counts the number of tokens in a text string.\"\"\"\n",
    "    \n",
    "    encoding = tiktoken.get_encoding(encoding_name)  # Get the encoding based on the given name\n",
    "    tokens = encoding.encode(text)  # Convert the text into tokens\n",
    "    return len(tokens)  # Return the number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "609b795c-bbf5-4ad5-bfe7-4f0853746a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(\"hello world!\", 'cl100k_base')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".training-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
