{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wywCFaDQ39ic"
   },
   "source": [
    "In this notebook we will see how to interact with different LLMs through LlamaIndex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the required packages by executing the below commands in either Anaconda Prompt (in Windows) or Terminal (in Linux or Mac OS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install llama-index-llms-openai llama-index-llms-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cKlax-updNW-"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cKlax-updNW-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv('/home/santhosh/Projects/courses/Pinnacle/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "GOOGLE_API_KEY = os.environ['GOOGLE_API_KEY']\n",
    "HUGGINGFACE_API_KEY = os.environ['HUGGINGFACE_API_KEY']\n",
    "COHERE_API_KEY = os.environ[\"COHERE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8il00G0w6HBA"
   },
   "source": [
    "# OpenAI's LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "yxPcwFUQ6DKY",
    "outputId": "49910bb8-574c-4119-aebb-33f66d51888c"
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.llms import ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model='gpt-4o-mini') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vN7jmOuH7SBs"
   },
   "source": [
    "### Call complete with a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "yREsde0o7NPT",
    "outputId": "d22ae3d3-3301-41fc-ceb3-305472b668f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Welcome to the Analytics Vidhya Community!\n",
      "\n",
      "Dear [Member's Name],\n",
      "\n",
      "Welcome to the Analytics Vidhya community!\n",
      "\n",
      "We are thrilled to have you join our vibrant and diverse group of data enthusiasts, professionals, and learners. At Analytics Vidhya, we believe in the power of data to transform businesses, industries, and lives. Our community is dedicated to fostering knowledge sharing, collaboration, and growth in the field of analytics, data science, and artificial intelligence.\n",
      "\n",
      "Here’s what you can look forward to as a member of our community:\n",
      "\n",
      "1. **Learning Resources**: Access a wealth of articles, tutorials, and courses designed to help you enhance your skills and stay updated with the latest trends and technologies in data science and analytics.\n",
      "\n",
      "2. **Competitions and Hackathons**: Participate in exciting competitions and hackathons to test your skills, solve real-world problems, and win amazing prizes.\n",
      "\n",
      "3. **Networking Opportunities**: Connect with like-minded individuals, industry experts, and thought leaders. Share your experiences, seek advice, and collaborate on projects.\n",
      "\n",
      "4. **Webinars and Events**: Attend webinars, workshops, and conferences hosted by Analytics Vidhya and our partners. Gain insights from top professionals and stay ahead in your career.\n",
      "\n",
      "5. **Community Support**: Engage in discussions on our forums, ask questions, and get support from fellow community members and experts.\n",
      "\n",
      "To get started, we recommend you:\n",
      "- Explore our [Learning Paths](https://www.analyticsvidhya.com/learning-paths/)\n",
      "- Join ongoing [Competitions](https://datahack.analyticsvidhya.com/contest/all/)\n",
      "- Participate in discussions on our [Forums](https://discuss.analyticsvidhya.com/)\n",
      "- Follow us on [LinkedIn](https://www.linkedin.com/company/analytics-vidhya/), [Twitter](https://twitter.com/AnalyticsVidhya), and [Facebook](https://www.facebook.com/AnalyticsVidhya/) for the latest updates.\n",
      "\n",
      "If you have any questions or need assistance, please do not hesitate to reach out to us at [support@analyticsvidhya.com](mailto:support@analyticsvidhya.com).\n",
      "\n",
      "Once again, welcome to the Analytics Vidhya community. We are excited to see the amazing things you will achieve and contribute!\n",
      "\n",
      "Best Regards,\n",
      "\n",
      "[Your Name]  \n",
      "Community Manager  \n",
      "Analytics Vidhya  \n",
      "[Website URL]  \n",
      "[Contact Information]\n",
      "\n",
      "P.S. Don’t forget to introduce yourself on our forums and let us know what you’re passionate about in the world of data science!\n",
      "\n",
      "---\n",
      "\n",
      "Feel free to customize this template to better fit your community's tone and specific offerings.\n"
     ]
    }
   ],
   "source": [
    "# Use the model to complete a prompt\n",
    "response = llm.complete(\"Write a welcome mail to the community members of Analytics Vidhya.\")\n",
    "\n",
    "# Print the generated response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-9YtW8nd5UldhrW5ZpisaWwO5qkuTg',\n",
       " 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Subject: Welcome to the Analytics Vidhya Community!\\n\\nDear [Member's Name],\\n\\nWelcome to the Analytics Vidhya community!\\n\\nWe are thrilled to have you join our vibrant and diverse group of data enthusiasts, professionals, and learners. At Analytics Vidhya, we believe in the power of data to transform businesses, industries, and lives. Our community is dedicated to fostering knowledge sharing, collaboration, and growth in the field of analytics, data science, and artificial intelligence.\\n\\nHere’s what you can look forward to as a member of our community:\\n\\n1. **Learning Resources**: Access a wealth of articles, tutorials, and courses designed to help you enhance your skills and stay updated with the latest trends and technologies in data science and analytics.\\n\\n2. **Competitions and Hackathons**: Participate in exciting competitions and hackathons to test your skills, solve real-world problems, and win amazing prizes.\\n\\n3. **Networking Opportunities**: Connect with like-minded individuals, industry experts, and thought leaders. Share your experiences, seek advice, and collaborate on projects.\\n\\n4. **Webinars and Events**: Attend webinars, workshops, and conferences hosted by Analytics Vidhya and our partners. Gain insights from top professionals and stay ahead in your career.\\n\\n5. **Community Support**: Engage in discussions on our forums, ask questions, and get support from fellow community members and experts.\\n\\nTo get started, we recommend you:\\n- Explore our [Learning Paths](https://www.analyticsvidhya.com/learning-paths/)\\n- Join ongoing [Competitions](https://datahack.analyticsvidhya.com/contest/all/)\\n- Participate in discussions on our [Forums](https://discuss.analyticsvidhya.com/)\\n- Follow us on [LinkedIn](https://www.linkedin.com/company/analytics-vidhya/), [Twitter](https://twitter.com/AnalyticsVidhya), and [Facebook](https://www.facebook.com/AnalyticsVidhya/) for the latest updates.\\n\\nIf you have any questions or need assistance, please do not hesitate to reach out to us at [support@analyticsvidhya.com](mailto:support@analyticsvidhya.com).\\n\\nOnce again, welcome to the Analytics Vidhya community. We are excited to see the amazing things you will achieve and contribute!\\n\\nBest Regards,\\n\\n[Your Name]  \\nCommunity Manager  \\nAnalytics Vidhya  \\n[Website URL]  \\n[Contact Information]\\n\\nP.S. Don’t forget to introduce yourself on our forums and let us know what you’re passionate about in the world of data science!\\n\\n---\\n\\nFeel free to customize this template to better fit your community's tone and specific offerings.\", role='assistant', function_call=None, tool_calls=None))],\n",
       " 'created': 1718103588,\n",
       " 'model': 'gpt-4o-2024-05-13',\n",
       " 'object': 'chat.completion',\n",
       " 'system_fingerprint': 'fp_319be4768e',\n",
       " 'usage': CompletionUsage(completion_tokens=535, prompt_tokens=21, total_tokens=556)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw response from the LLM\n",
    "response.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the raw dict keys from the response\n",
    "type(response.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'choices', 'created', 'model', 'object', 'system_fingerprint', 'usage'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.raw.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=535, prompt_tokens=21, total_tokens=556)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the tokens usage from the raw response (remember \"raw\" is a dict)\n",
    "response.raw[\"usage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.raw[\"usage\"].dict()[\"completion_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.raw[\"usage\"].dict()[\"total_tokens\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_R4dvP787gT6"
   },
   "source": [
    "### Call chat with a list of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "nwiWxJM97YaY",
    "outputId": "cf99685c-8edc-4da6-b497-0b50c0dbd313"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are an AI assistant that talks like Elon Musk.\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"Write a welcome mail to the community members of Analytics Vidhya.\"),\n",
    "]\n",
    "\n",
    "response = OpenAI().chat(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the response into dict and fetch the keys\n",
    "response.dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the \"content\" from the message attribute\n",
    "response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.message.content)   # total number of characters in the response message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the \"raw\" response from the LLM\n",
    "response.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the tokens usage stats from the raw response\n",
    "response.raw[\"usage\"].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the completion_tokens, prompt_tokens & total_tokens form usage\n",
    "response.raw[\"usage\"].dict()[\"prompt_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.raw[\"usage\"].dict()[\"total_tokens\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxNHcLYYW9m3"
   },
   "source": [
    "### Using stream_chat endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between `chat` and `stream_chat` is how they handle the response from the AI model. The previous code waits for the full response before printing it, while the `stream_chat` streams the response in chunks and prints each chunk as it is received. This can provide a more interactive experience, especially for longer texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0wqjnNwWwe_",
    "outputId": "dc4fa5c9-5ff2-4da3-ca6a-ead95d3e9b46"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are an AI assistant that talks like Master Yoda from the Star Wars.\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"Write a welcome mail to the community members of Analytics Vidhya.\"),\n",
    "]\n",
    "\n",
    "response = llm.stream_chat(messages)\n",
    "\n",
    "for r in response:\n",
    "  print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oA1GT1MXQv9"
   },
   "source": [
    "### Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mtCmLwmXKox"
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.7, max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqaxpLd4xCAf"
   },
   "outputs": [],
   "source": [
    "response = llm.complete(\"Write a welcome mail to the community members of Analytics Vidhya.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.2, max_tokens=100,  additional_kwargs={\"seed\": 12345678, \"top_p\": 0.5})\n",
    "response = llm.complete(\"Explain the concept of gravity in one sentence\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2lBstRkXaSP"
   },
   "source": [
    "#### Call chat with a list of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inABtoqCXaSP",
    "outputId": "96afc602-1dd8-4a94-f0e5-6410306baa9e"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are an AI assistant that talks like Elon Musk.\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"Write a welcome mail to the community members of Analytics Vidhya.\"),\n",
    "]\n",
    "\n",
    "response = llm.chat(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z76JbeZgvLUO"
   },
   "source": [
    "## Using Anthropic LLM API (Paid model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zl7lxVjzvOSY"
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Anthropic(model='claude-3-5-sonnet-20241022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptiMqr4LvOUq"
   },
   "outputs": [],
   "source": [
    "response = llm.complete(\"Write a welcome mail to the community members of Analytics Vidhya.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkQUCVTHxEn9"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are an AI assistant that talks like a elon musk.\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"Write a welcome mail to the community members of Analytics Vidhya.\"),\n",
    "]\n",
    "\n",
    "response = llm.chat(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "64bcadabe4cd61f3d117ba0da9d14bf2f8e35582ff79e821f2e71056f2723d1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
